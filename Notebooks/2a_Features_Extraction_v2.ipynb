{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15f8a81",
   "metadata": {},
   "source": [
    "# 2a Features Extraction\n",
    "\n",
    "Runs:\n",
    "- Imports & Functions [Jump To](#run-0-all-imports-etc)\n",
    "- Study Load & Inspections [Jump To](#run-1-study-load--inspections)\n",
    "- Feature Selection [Jump To](#run-2-feature-selections)\n",
    "\n",
    "To Do:\n",
    "- ?? Rejection of channels, subjects ....\n",
    "- ?? Use of canonical bands\n",
    "- Data prep, save data results for ML training / ML Execution .... or pipeline rerun?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca9bf7",
   "metadata": {},
   "source": [
    "# Imports & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39158ea0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86388717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import warnings\n",
    "from typing import Literal\n",
    "\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Custom Functions\n",
    "sys.path.append(os.path.abspath('../Notebooks/Utilities')) \n",
    "import cust_utilities as utils\n",
    "\n",
    "# Maths, Pandas etc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sci\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ML Prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "# ML Training\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ed1b6",
   "metadata": {},
   "source": [
    "## Results & Features Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca539e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for subject info\n",
    "#\n",
    "\n",
    "def subject_info_plot(subjects_df):\n",
    "\n",
    "    # PD & Gender\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    fig.suptitle('Study Subjects - PD & Gender', fontsize=18)\n",
    "\n",
    "    counts = subjects_df['pd'].value_counts()\n",
    "    axes[0].set_title('PD')\n",
    "    axes[0].bar(counts.index.astype(str), counts.values, color=['skyblue', 'skyblue'], edgecolor='black')\n",
    "    axes[0].set_xticks(range(len(counts.index)))\n",
    "    axes[0].set_xticklabels(['Yes', 'No'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[0].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    counts = subjects_df['gender'].value_counts()\n",
    "    axes[1].set_title('Gender')\n",
    "    axes[1].bar(counts.index.astype(str), counts.values, color=['skyblue', 'skyblue'], edgecolor='black')\n",
    "    axes[1].set_xticks(range(len(counts.index)))\n",
    "    axes[1].set_xticklabels(['Male', 'Female'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[1].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Age Distribution & Box\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    fig.suptitle('Study Subjects - Age Distribution', fontsize=18)\n",
    "\n",
    "    axes[0].hist(subjects_df['age'], bins=15, color='skyblue', edgecolor='black')\n",
    "\n",
    "    axes[1].set_xticks([0])\n",
    "    box = axes[1].boxplot(subjects_df['age'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9095073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for EEG Preprocessing Results\n",
    "#\n",
    "\n",
    "def eeg_preprocess_results_plot(results_df):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "    fig.suptitle('EEG Preprocessing Metrics - All Subjects', fontsize=18)\n",
    "\n",
    "    # Quality Warning\n",
    "    counts = results_df['EEG_preprocessing_quality_warning'].value_counts().reindex([True, False], fill_value=0)\n",
    "    axes[0].set_title('Overall Quality Warning Count')\n",
    "    axes[0].bar(counts.index.astype(str), counts.values, color=['salmon', 'lightgreen'], edgecolor='black')\n",
    "    axes[0].set_xticks(range(len(counts.index)))\n",
    "    axes[0].set_xticklabels(['Yes', 'No'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[0].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    # # Channels count\n",
    "    # counts = results_df['channel_count'].value_counts()\n",
    "    # axes[1].set_title('Channels Count')\n",
    "    # axes[1].bar(counts.index.astype(str), counts.values, color=['skyblue'], edgecolor='black')\n",
    "\n",
    "    # ICA Rejection Level\n",
    "    axes[1].set_title('ICA - ICs Rejection Level')\n",
    "    box = axes[1].boxplot(results_df['ICA_rejection_level'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # Epoch Rejection Level\n",
    "    axes[2].set_title('Epoch Rejection Level')\n",
    "    box = axes[2].boxplot(results_df['epoch_rejection_level'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "    # axes[2].set_xlabel('Epoch Rejection Level')\n",
    "    # axes[2].set_ylabel('Number of Subjects')\n",
    "    # axes[2].hist(results_df['epoch_rejection_level'], bins=10, color='skyblue', edgecolor='black')\n",
    "    # nonzero_epoch_rejection = results_df['epoch_rejection_level'][results_df['epoch_rejection_level'] > 0]\n",
    "    # axes[2].hist(nonzero_epoch_rejection, bins=15, color='salmon', edgecolor='black', alpha=0.7)\n",
    "    # for bar in axes[2].patches:\n",
    "    #     bar.set_width(bar.get_width() * 0.8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d485d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for EEG SpecParam Results\n",
    "#\n",
    "\n",
    "def eeg_specparam_results_plot(results_df):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "    fig.suptitle('EEG SpecParam Fit Metrics - All Subjects', fontsize=18)\n",
    "\n",
    "    # Quality Warning\n",
    "    counts = results_df['chn_SPM_fit_quality_warning'].value_counts().reindex([True, False], fill_value=0)\n",
    "    axes[0].set_title('Overall Quality Warning Count')\n",
    "    axes[0].bar(counts.index.astype(str), counts.values, color=['salmon', 'lightgreen'], edgecolor='black')\n",
    "    \n",
    "    axes[0].set_xticks(range(len(counts.index)))\n",
    "    axes[0].set_xticklabels(['Yes', 'No'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[0].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    # Error Mean\n",
    "    axes[1].set_title('Error Mean')\n",
    "    box = axes[1].boxplot(results_df['chn_error_mean'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # R-Squared Mean\n",
    "    axes[2].set_title('R2 Mean')\n",
    "    box = axes[2].boxplot(results_df['chn_r2_mean'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Number of flagged channels\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(3, 4))\n",
    "    # fig.suptitle('EEG SpecParam Fit Metrics - Flagged Channels', fontsize=18)\n",
    "    flagged_counts = results_df['chn_flagged_channels'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    axes.set_title('Flagged Channels Count')\n",
    "    box = axes.boxplot(flagged_counts, patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='salmon')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd93eb",
   "metadata": {},
   "source": [
    "# Run: 0. All Imports etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e2e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy - Run All above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba6e54",
   "metadata": {},
   "source": [
    "# Run: 1. Study Load & Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a8e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study and Processing Run Details\n",
    "\n",
    "#---- Parameters --------------------------------\n",
    "# Study & Processing Run Details\n",
    "study_name = 'IOWA_Rest'\n",
    "eeg_features_run = '1b_EEG_Features_Results_Run_20250724_full_run'\n",
    "\n",
    "run_description = 'test_extraction'\n",
    "test_mode = True\n",
    "\n",
    "# Extraction Parameters\n",
    "extraction_params = {}\n",
    "# TODO: Add selection etc parameters here\n",
    "#----------------------------------------------------\n",
    "\n",
    "# Get existing study details, if exists\n",
    "study_folder_path = utils.get_folder_path('Study_' + study_name)\n",
    "study_info = pd.read_pickle(study_folder_path + '/study_inf.pkl', compression='zip')\n",
    "study_subjects_df = pd.read_pickle(study_folder_path + '/study_subjects_df.pkl', compression='zip')\n",
    "\n",
    "# Processing Results Data\n",
    "eeg_features_run_results_path = utils.get_folder_path(study_info['eeg_processing_results_path'] + '/' + eeg_features_run)\n",
    "eeg_features_run_details = pd.read_pickle(eeg_features_run_results_path + '/run_details.pkl', compression='zip')\n",
    "eeg_preprocessing_run = eeg_features_run_details['eeg_preprocessed_data']\n",
    "\n",
    "eeg_preprocessing_run_results_path = utils.get_folder_path(study_info['eeg_processing_results_path'] + '/' + eeg_preprocessing_run)\n",
    "eeg_preprocessed_data_path = utils.get_folder_path(eeg_preprocessing_run_results_path + '/Cleaned_files' )\n",
    "eeg_preprocessing_run_details = pd.read_pickle(eeg_preprocessing_run_results_path + '/run_details.pkl', compression='zip')\n",
    "eeg_processing_results_df = pd.read_pickle(eeg_features_run_results_path + '/eeg_processing_results_df.pkl', compression='zip')\n",
    "eeg_features_superset_df = pd.read_pickle(eeg_features_run_results_path + '/eeg_features_superset_df.pkl', compression='zip')\n",
    "\n",
    "# Setup the extraction run and results folder & save params\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "run_name = f'2a_Feature_Extraction_Data_Run_{current_date}_{run_description}'\n",
    "run_results_path = utils.extend_folder_path(study_info['ml_training_results_path'], run_name, exists_ok=False)\n",
    "\n",
    "run_details = pd.Series({\n",
    "    'study_name': study_name,\n",
    "    'run_name': run_name,\n",
    "    'extraction_params': extraction_params,\n",
    "})\n",
    "run_details.to_pickle(run_results_path + '/run_details.pkl', compression='zip')\n",
    "\n",
    "# Set progress messages, testing\n",
    "if test_mode:\n",
    "    VERBOSE = True\n",
    "    TEST_SUBJECTS = [0,5,101]\n",
    "    # TEST_CHANNELS = ['F5', 'C3', 'P3', 'F6', 'C6', 'P6']\n",
    "else:\n",
    "    VERBOSE = False\n",
    "    TEST_SUBJECTS = []\n",
    "    # TEST_CHANNELS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db334c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Run Details & Data Structures\n",
    "summary = f'EEG Processing Parameters'\n",
    "summary = summary + f\"\\n- Study: {study_info['study_name']} {study_info['dataset_ref']}\"\n",
    "summary = summary + f\"\\n- EEG Processing Run: {eeg_preprocessing_run_details['run_name']}\"\n",
    "summary = summary + f\"\\n-   Preprocess Params: {eeg_preprocessing_run_details['preprocess_params']}\"\n",
    "summary = summary + f\"\\n-   ICA Params: {eeg_preprocessing_run_details['artefact_params']}\"\n",
    "summary = summary + f\"\\n- EEG Features Run: {eeg_features_run}\"\n",
    "summary = summary + f\"\\n-   PSD Params: {eeg_features_run_details['psd_params']}\"\n",
    "summary = summary + f\"\\n-   SpecParam Params: {eeg_features_run_details['specparam_params']}\"\n",
    "summary = summary + f\"\\n- Features Extraction Run: {run_name}\"\n",
    "summary = summary + f\"\\n-   Feature Extraction Params: {run_details['extraction_params']}\"\n",
    "print(f'{summary}\\n')\n",
    "\n",
    "# Processing Metrics\n",
    "print('EEG Processing Results')\n",
    "print(eeg_processing_results_df.shape)\n",
    "display(eeg_processing_results_df.head())\n",
    "\n",
    "print(f'Null Fits: {sum(eeg_processing_results_df[\"chn_null_fits\"])}')\n",
    "eeg_preprocess_results_plot(eeg_processing_results_df)\n",
    "eeg_specparam_results_plot(eeg_processing_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study Subjects Summary\n",
    "print('Study Subjects')\n",
    "print(study_subjects_df.shape)\n",
    "display(study_subjects_df.head())\n",
    "\n",
    "subject_info_plot(study_subjects_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a1865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine eeg_features_superset_df with study_subjects_df so each subject has one row\n",
    "# and columns are named with channel/region prefixes\n",
    "\n",
    "def combine_features_with_subjects(features_df, subjects_df, valid_regions):\n",
    "    subjects = subjects_df['subject_id'].unique()\n",
    "    combined_rows = []\n",
    "    for subj_id in subjects:\n",
    "        subj_features = features_df[features_df['subject_id'] == subj_id]\n",
    "        row = {'subject_id': subj_id}\n",
    "        # Add subject meta info\n",
    "        subj_meta = subjects_df.loc[subjects_df['subject_id'] == subj_id, ['pd', 'age', 'gender']].iloc[0]\n",
    "        row.update(subj_meta.to_dict())\n",
    "        # For each channel/region, add features with prefix\n",
    "        for _, feat_row in subj_features.iterrows():\n",
    "            ch = feat_row['channel']\n",
    "            prefix = f\"{ch}_\" if ch not in valid_regions else f\"{ch}_region_\"\n",
    "            for col in feat_row.index:\n",
    "                if col in ['subject_id', 'channel']:\n",
    "                    continue\n",
    "                row[f\"{prefix}{col}\"] = feat_row[col]\n",
    "        combined_rows.append(row)\n",
    "    combined_df = pd.DataFrame(combined_rows)\n",
    "    return combined_df\n",
    "\n",
    "combined_features_df = combine_features_with_subjects(eeg_features_superset_df, study_subjects_df, valid_regions)\n",
    "print('Combined Features DataFrame')\n",
    "print(combined_features_df.shape)\n",
    "display(combined_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651215d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Features DataFrame\n",
      "(149, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_name</th>\n",
       "      <th>pd</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-001</td>\n",
       "      <td>IOWA_Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>IOWA_Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-003</td>\n",
       "      <td>IOWA_Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-004</td>\n",
       "      <td>IOWA_Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-005</td>\n",
       "      <td>IOWA_Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id study_name  pd  age gender\n",
       "0    sub-001  IOWA_Rest   1   80      M\n",
       "1    sub-002  IOWA_Rest   1   81      M\n",
       "2    sub-003  IOWA_Rest   1   68      F\n",
       "3    sub-004  IOWA_Rest   1   80      M\n",
       "4    sub-005  IOWA_Rest   1   56      M"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the subject 'meta' df and EEG features df\n",
    "# With one row per subject and seversl hundred 'features'\n",
    "\n",
    "def combine_subjects_features(subjects_df, features_df):\n",
    "    subjects_features = []\n",
    "\n",
    "    subjects = subjects_df['subject_id'].unique()\n",
    "    for subj_id in subjects:\n",
    "        subj_meta = subjects_df.loc[subjects_df['subject_id'] == subj_id].iloc[0].to_dict()\n",
    "        subj_features = features_df[features_df['subject_id'] == subj_id]\n",
    "\n",
    "        # Subject ID & Meta data\n",
    "        row_dict = {'subject_id': subj_id}\n",
    "        row_dict.update(subj_meta)\n",
    "\n",
    "        # Flattened Region & Channel data\n",
    "\n",
    "\n",
    "\n",
    "        subjects_features.append(row_dict)\n",
    "    \n",
    "    combined_df = pd.DataFrame(subjects_features)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "test = combine_subjects_features(study_subjects_df, eeg_features_superset_df)\n",
    "print('Combined Features DataFrame')\n",
    "print(test.shape)\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84559552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Superset \n",
    "print('EEG Features Superset')\n",
    "print(eeg_features_superset_df.shape)\n",
    "display(eeg_features_superset_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpecParam Results\n",
    "\n",
    "# TODO: Summary of features? What detail ............ \n",
    "\n",
    "# aperiodic_components_plot(eeg_features_superset_df)\n",
    "# periodic_components_plot(eeg_features_superset_df)\n",
    "# Adapt from xx Features Extraction, xx Model Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba79ccc",
   "metadata": {},
   "source": [
    "# New Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748489d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using a Custom Transformer class\n",
    "#\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FeaturesSelection(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, features_detail_level):\n",
    "        # Parameters for the selection\n",
    "        self.features_detail_level = features_detail_level\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_temp_df = X.copy()\n",
    "        else:\n",
    "            raise ValueError(\"X must be a pandas DataFrame for feature selection.\")\n",
    "        \n",
    "        # Feature selection training / fit\n",
    "\n",
    "        # TODO: Temp test\n",
    "        print(f'Trace: Feature Selection with: {self.features_detail_level}')\n",
    "        temp_cols_to_retain = ['subject_id', 'channel'] + ['exponent']\n",
    "        X_temp_df = X_temp_df[[col for col in X_temp_df.columns if any(name in col for name in temp_cols_to_retain)]]\n",
    "        print(f'Trace Selected DF')\n",
    "        print(X_temp_df.head())\n",
    "\n",
    "        self.selected_features_ = list(X_temp_df)\n",
    "        print(f'Trace: Selected Features {self.selected_features_}')\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_temp_df = X.copy()\n",
    "        else:\n",
    "            raise ValueError(\"X must be a pandas DataFrame for feature selection.\")\n",
    "        \n",
    "        # Apply feature selection\n",
    "        return X[self.selected_features_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157de8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = eeg_features_superset_df.copy()\n",
    "X_test = eeg_features_superset_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df96624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to drop\n",
    "features_to_drop = ['subject_id']\n",
    "def drop_features(df, features):\n",
    "    return df.drop(features, axis=1)\n",
    "dropper = FunctionTransformer(drop_features, kw_args={'features': features_to_drop} )\n",
    "\n",
    "# # Numerical Scaling & Cat Encoding Column Transformations\n",
    "# temp = X_train.drop(features_to_drop, axis=1)\n",
    "# numerical_cols = temp.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "# categorical_cols = temp.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scale_num', RobustScaler()) # TODO: vs standardscaler?\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "    # (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    # (\"encode_cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "    ('encode_cat', OneHotEncoder(drop='first', handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "# cols_transform = ColumnTransformer([\n",
    "#     ('numeric', num_pipeline, numerical_cols),\n",
    "#     ('categorical', cat_pipeline, categorical_cols)\n",
    "#     ])\n",
    "cols_transform = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, make_column_selector(dtype_include=['float64', 'int64'])),\n",
    "    ('categorical', cat_pipeline, make_column_selector(dtype_include='object'))\n",
    "])\n",
    "\n",
    "# Establish and train/fit the overall preparation pipeline\n",
    "features_prep_pipeline = Pipeline([\n",
    "    ('test_fs', FeaturesSelection('Regions')),\n",
    "    ('drop_columns', dropper),\n",
    "    ('data_preprocess', cols_transform)\n",
    "    ])  \n",
    "features_prep_pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline([\n",
    "    ('test_fs', FeaturesSelection('Regions'))\n",
    "])\n",
    "\n",
    "test_pipeline.fit(eeg_features_superset_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = test_pipeline.transform(eeg_features_superset_df)\n",
    "X_test_transformed = test_pipeline.transform(eeg_features_superset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d38f72",
   "metadata": {},
   "source": [
    "# Run: 2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238324d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------\n",
    "# TODO: Add selection to notebook parameters\n",
    "FeatureDetailLevel = Literal['regions', 'channels']\n",
    "\n",
    "feature_detail_level: FeatureDetailLevel = 'channels'  # regions or channels\n",
    "# features_retained = ['offset', 'exponent']\n",
    "# features_retained = ['cf', 'pw', 'bw']\n",
    "features_retained = ['cf', 'pw', 'bw', 'offset', 'exponent']\n",
    "\n",
    "\n",
    "# TODO: Add to constants or change Superset with two columns, 'Regions' and 'Channels' then select on that\n",
    "valid_regions = ['frontal', 'central', 'posterior']\n",
    "id_columns = ['subject_id', 'channel']\n",
    "#-----------\n",
    "\n",
    "# TODO: Add more sophisticated selection, eg PCA etc?\n",
    "# TODO: Put this into a custom classifier class for use in a pipeline? Benefits? \n",
    "# TODO: Compare the impact of different feature selections, all, periodic, aperiodic, region, channel etc?\n",
    "# TODO: Even do this in a grid search but with a static model to avoid huge permutations and running time\n",
    "\n",
    "# Select Specific Features from the EEG Features Superset\n",
    "# Create selected features, flattened to one row/vector per subject\n",
    "#\n",
    "\n",
    "# Iterate through all subjects and filter features, rename columns etc\n",
    "#\n",
    "\n",
    "subjects = study_subjects_df['subject_id'].unique()\n",
    "columns_retained = id_columns + features_retained\n",
    "subjects_features = []\n",
    "for next_subj in subjects:\n",
    "    subj_df = eeg_features_superset_df[eeg_features_superset_df['subject_id'] == next_subj]\n",
    "\n",
    "    # Retain defined level of detail: regions or channels\n",
    "    if feature_detail_level == 'regions':\n",
    "        subj_df = subj_df[subj_df['channel'].isin(valid_regions)]\n",
    "    else:\n",
    "        subj_df = subj_df[~subj_df['channel'].isin(valid_regions)]\n",
    "    \n",
    "    # Drop columns not in retained features\n",
    "    subj_df = subj_df[[col for col in subj_df.columns if any(name in col for name in columns_retained)]]\n",
    "    \n",
    "    # Iterate through subject channels to combine into one row\n",
    "    row_dict = {'subject_id': next_subj}\n",
    "    channels = subj_df['channel'].unique()\n",
    "    for next_channel in channels:\n",
    "        ch_row = subj_df[subj_df['channel'] == next_channel]\n",
    "        for col_name in subj_df.columns:\n",
    "            if not any([col_name.startswith(feat) for feat in features_retained]):\n",
    "                continue\n",
    "            row_dict[f'{next_channel}_{col_name}'] = ch_row[col_name].item()\n",
    "    \n",
    "    # Add the subject meta data\n",
    "    subj_meta = study_subjects_df.loc[study_subjects_df['subject_id'] == next_subj, ['pd', 'age', 'gender']].iloc[0]\n",
    "    row_dict.update({'pd': subj_meta['pd'], 'age': subj_meta['age'], 'gender': subj_meta['gender']})\n",
    "    \n",
    "    subjects_features.append(row_dict)\n",
    "\n",
    "# Create slected features dataframe\n",
    "features_selection_df = pd.DataFrame(subjects_features)\n",
    "print('Features Selection')\n",
    "print(features_selection_df.shape)\n",
    "display(features_selection_df.head())\n",
    "\n",
    "# TODO: Save features selection df .... for rerunning ... or use a saved scikit pipeline pipeline custom classifier?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44d677",
   "metadata": {},
   "source": [
    "# Run: 3. Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de33eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X features and y target\n",
    "# TODO: Separate notebook and load selected fetaures df?\n",
    "\n",
    "target_col_name = 'pd'\n",
    "feature_names = features_selection_df.columns[features_selection_df.columns != target_col_name]\n",
    "X = features_selection_df[feature_names].copy()\n",
    "y = features_selection_df[target_col_name].copy()\n",
    "\n",
    "# Data Split : Training & Test, 80:20. NB cross-validation will be performed using Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TODO: Different split?\n",
    "# split by *subjects*, not by raw rows\n",
    "# train_subj, test_subj = train_test_split(subjects, stratify=labels,\n",
    "#                                          test_size=.3, random_state=42)\n",
    "# X_train = eeg_long[eeg_long.subject_id.isin(train_subj)]\n",
    "# X_test  = eeg_long[eeg_long.subject_id.isin(test_subj)]\n",
    "# y_train = labels.loc[train_subj].values\n",
    "# y_test  = labels.loc[test_subj].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Cleaning - Pipeline Setup\n",
    "#\n",
    "\n",
    "# TODO: Compare no scaling at all and model performance\n",
    "\n",
    "# Features to drop\n",
    "features_to_drop = ['subject_id']\n",
    "def drop_features(df, features):\n",
    "    return df.drop(features, axis=1)\n",
    "dropper = FunctionTransformer(drop_features, kw_args={'features': features_to_drop} )\n",
    "\n",
    "# # Numerical Scaling & Cat Encoding Column Transformations\n",
    "# temp = X_train.drop(features_to_drop, axis=1)\n",
    "# numerical_cols = temp.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "# categorical_cols = temp.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scale_num', RobustScaler()) # TODO: vs standardscaler?\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "    # (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    # (\"encode_cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "    ('encode_cat', OneHotEncoder(drop='first', handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "# cols_transform = ColumnTransformer([\n",
    "#     ('numeric', num_pipeline, numerical_cols),\n",
    "#     ('categorical', cat_pipeline, categorical_cols)\n",
    "#     ])\n",
    "cols_transform = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, make_column_selector(dtype_include=['float64', 'int64'])),\n",
    "    ('categorical', cat_pipeline, make_column_selector(dtype_include='object'))\n",
    "])\n",
    "\n",
    "# Establish and train/fit the overall preparation pipeline\n",
    "features_prep_pipeline = Pipeline([\n",
    "    # TODO: Feature Selection custom class?\n",
    "    ('drop_columns', dropper),\n",
    "    ('data_preprocess', cols_transform)\n",
    "    ])  \n",
    "features_prep_pipeline.fit(X_train)\n",
    "\n",
    "# TODO: Save pipleline for later reuse alongside the trained ML model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a18da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformations to training data\n",
    "\n",
    "X_train_transformed = features_prep_pipeline.transform(X_train)\n",
    "X_test_transformed = features_prep_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint - Tranformation Results\n",
    "\n",
    "# TODO: Examine the impact of scaling etc more closely eg some boxplots before and after .... how well has eg scaling worked?\n",
    "\n",
    "# Before & After\n",
    "print(\"Features Extraction / Transformed Data\")\n",
    "print(f'- Original Features Selection: {features_selection_df.shape}')\n",
    "print(f'- Original X_train: {X_train.shape} and y_train: {y_train.shape}')\n",
    "print(f'- Original X_test: {X_test.shape} and y_test: {y_test.shape}')\n",
    "print(f'- Transformed X_train: {X_train_transformed.shape}')\n",
    "print(f'- Transformed X_test: {X_test_transformed.shape}')\n",
    "print(f'- Num feature names from pipeline: {len(cols_transform.get_feature_names_out())}')\n",
    "\n",
    "# Feature Names\n",
    "# print(\"\\nFeature Names\")\n",
    "# print(\"Numerical:\", len(numerical_cols), numerical_cols[:5] if numerical_cols else \"None\")\n",
    "# print(\"Categorical:\", len(categorical_cols), categorical_cols[:5] if categorical_cols else \"None\")\n",
    "\n",
    "print(\"\\nTransformed\")\n",
    "temp_names_X_train_df = pd.DataFrame(X_train_transformed, columns=cols_transform.get_feature_names_out())\n",
    "temp_names_X_train_df.reset_index(drop=True, inplace=True)\n",
    "# print(list(temp_names_X_train_df.columns[:]))\n",
    "# print(\"\\nHead of X_train_transformed:\")\n",
    "display(temp_names_X_train_df.head())\n",
    "\n",
    "# Check the pipeline structure\n",
    "print(\"Pipeline transformers:\")\n",
    "for name, transformer, columns in cols_transform.transformers_:\n",
    "    print(f\"- {name}: {len(columns) if hasattr(columns, '__len__') else 'Unknown'} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a14c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint - Pipeline\n",
    "\n",
    "print(\"Feature Extraction Pipeline Steps:\")\n",
    "for name, step in features_prep_pipeline.named_steps.items():\n",
    "    print(f\"- {name}: {step}\")\n",
    "\n",
    "print(\"\\nColumnTransformer Details:\")\n",
    "ct = features_prep_pipeline.named_steps['data_preprocess']\n",
    "for name, trans, cols in ct.transformers_:\n",
    "    print(f\"- Transformer: {name}\")\n",
    "    print(f\"    Columns: {cols}\")\n",
    "    print(f\"    Transformer object: {trans}\\n\")\n",
    "\n",
    "print(\"\\nAll Pipeline Parameters\")\n",
    "for param, value in features_prep_pipeline.get_params().items():\n",
    "    print(f\"- {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for problematic data\n",
    "# print(\"Numerical data info:\")\n",
    "# print(X_train[numerical_cols].describe())\n",
    "# print(\"\\nAny infinite values?\", np.isinf(X_train[numerical_cols]).any().any())\n",
    "# print(\"Any NaN values?\", X_train[numerical_cols].isnull().any().any())\n",
    "\n",
    "# # Check if all numerical columns have the same values (zero variance)\n",
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# var_selector = VarianceThreshold(threshold=0)\n",
    "# var_selector.fit(X_train[numerical_cols])\n",
    "# print(\"Columns with zero variance:\", \n",
    "#       [col for col, keep in zip(numerical_cols, var_selector.get_support()) if not keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4b741",
   "metadata": {},
   "source": [
    "# 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294cee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Display The Model Fit Results\n",
    "\n",
    "def print_search_results(search, duration):\n",
    "    print('------- Search Results --------')\n",
    "    all_search_results = pd.DataFrame(search.cv_results_)\n",
    "    print(f\"Score: {search.best_score_:.4f}. Mean: {np.mean(all_search_results['mean_test_score']):.4f} and STD {np.std(all_search_results['mean_test_score']):.4f}\")\n",
    "    print(f'Search Took: {duration:.2f} seconds')\n",
    "    print(f\"Best Parameters: {search.best_params_}\")\n",
    "    \n",
    "    top_n = 10\n",
    "    print(f\"Top {top_n} out of {len(all_search_results)} combinations:\")\n",
    "    display(all_search_results[['rank_test_score', 'mean_test_score', 'mean_fit_time', 'mean_score_time', 'params']].sort_values(by='rank_test_score').head(top_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeecf08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Present the Evaluation Metrics for a Classification Model\n",
    "\n",
    "def classification_metrics(for_Model, X_test, y_test, y_pred):\n",
    "    plt.style.use('default')\n",
    "\n",
    "    # Calculate Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Print various metrics\n",
    "    print(f'Accuracy: {metrics.accuracy_score(y_true=y_test, y_pred=y_pred):.4f}')\n",
    "    print(f'Precision: {metrics.precision_score(y_true=y_test, y_pred=y_pred, pos_label=1):.4f}')\n",
    "    print(f'Recall: {metrics.recall_score(y_true=y_test, y_pred=y_pred, pos_label=1):.4f}')\n",
    "    print(f'F1 Score {metrics.f1_score(y_true=y_test, y_pred=y_pred, pos_label=1):.4f}')\n",
    "    print(f'Specificity: {tn / (tn + fp):.4f}')\n",
    "    print(f'Hamming Loss {metrics.hamming_loss(y_true=y_test, y_pred=y_pred):.4f}')\n",
    "\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    class_labels = for_Model.classes_\n",
    "    fig, ax = plt.subplots(figsize=(12,4))\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels).plot(ax=ax)\n",
    "    plt.show\n",
    "\n",
    "    y_probabilities = for_Model.predict_proba(X_test)[:, 1]\n",
    "    roc_auc_score = metrics.roc_auc_score(y_true=y_test, y_score=y_probabilities)\n",
    "    print(f'ROC-AUC Score {roc_auc_score:.4f}')\n",
    "    gini_score = 2 * roc_auc_score - 1\n",
    "    print(f'Gini Index: {gini_score:.4f}')\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.set_title('ROC Curve')\n",
    "    roc_display = RocCurveDisplay.from_estimator(for_Model, X_test, y_test, ax=ax, pos_label=1)\n",
    "    plt.show()\n",
    "\n",
    "    plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a Model Pipeline - Using Processed Data\n",
    "#\n",
    "\n",
    "# Pipeline, params & grid search define\n",
    "model_pipeline = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1, verbose=False))\n",
    "    ])\n",
    "\n",
    "grid_params = {\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss'],     # Default gini. Tree split evaluation function\n",
    "    'classifier__n_estimators': [150, 175],                       # Default 100. Number of trees\n",
    "    'classifier__max_depth': [2, 10, None],                          # Default none, unlimited\n",
    "    'classifier__max_leaf_nodes': [50, None],                     # Default none, unlimited\n",
    "    # 'randomforestclassifier__min_samples_split': [2, 5],\n",
    "    # 'classifier__class_weight': [None, 'balanced']\n",
    "                            # Balanced gives more importance to minority classes ... ?? Improves recall at the expense of precision\n",
    "    } \n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model_pipeline, grid_params, \n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    "    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search run\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "duration = time.perf_counter() - start_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f071f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint - ML Pipeline\n",
    "\n",
    "# print(\"Feature Extraction Pipeline Steps:\")\n",
    "# for name, step in model_pipeline.named_steps.items():\n",
    "#     print(f\"- {name}: {step}\")\n",
    "\n",
    "print(\"\\nAll Pipeline Parameters\")\n",
    "for param, value in model_pipeline.get_params().items():\n",
    "    print(f\"- {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search results\n",
    "print_search_results(grid_search, duration)\n",
    "\n",
    "# Get the Best Model & Calculate Predicted Y and Evaluate\n",
    "model_randforest = grid_search.best_estimator_\n",
    "y_pred = model_randforest.predict(X_test_transformed)\n",
    "classification_metrics(model_randforest, X_test_transformed, y_test, y_pred)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = model_randforest.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Map feature importances to transformed feature names\n",
    "transformed_feature_names = cols_transform.get_feature_names_out()\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': transformed_feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "# Keep only the top 25 most important features\n",
    "importance_df = importance_df.head(25)\n",
    "\n",
    "# print(importance_df)\n",
    "\n",
    "# Plot the feature importances with names horizontally\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances (Sorted)')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature at the top\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_ml_pipeline_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
