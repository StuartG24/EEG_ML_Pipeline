{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15f8a81",
   "metadata": {},
   "source": [
    "# 2 ML Features Selection & Model Training\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaed2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save Current Session\n",
    "# import dill\n",
    "\n",
    "# dill.dump_session('temp_save_session.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a previous session\n",
    "# import dill\n",
    "\n",
    "# dill.load_session('temp_save_session.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca9bf7",
   "metadata": {},
   "source": [
    "# Imports & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39158ea0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86388717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import warnings\n",
    "from typing import Literal\n",
    "\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pickle\n",
    "import cloudpickle\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Custom Functions\n",
    "sys.path.append(os.path.abspath('../Notebooks/Utilities')) \n",
    "import cust_utilities as utils\n",
    "\n",
    "# Maths, Pandas etc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sci\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ML Prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "# ML Training\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "# from ml_utilities import ml_model_pipeline_details, grid_search_results\n",
    "# from ml_utilities import ml_model_pipeline_details, grid_search_results, classification_metrics \n",
    "# from ml_utilities import feature_importance, get_shap_importance, get_prediction_probabilities\n",
    "import shap\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ed1b6",
   "metadata": {},
   "source": [
    "## Functions - Results & Features Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca539e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for subject info\n",
    "#\n",
    "\n",
    "def subject_info_plot(subjects_df):\n",
    "\n",
    "    # PD & Gender\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    fig.suptitle('Study Subjects - PD & Gender', fontsize=18)\n",
    "\n",
    "    counts = subjects_df['pd'].value_counts()\n",
    "    axes[0].set_title('PD')\n",
    "    axes[0].bar(counts.index.astype(str), counts.values, color=['skyblue', 'skyblue'], edgecolor='black')\n",
    "    axes[0].set_xticks(range(len(counts.index)))\n",
    "    axes[0].set_xticklabels(['Yes', 'No'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[0].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    counts = subjects_df['gender'].value_counts()\n",
    "    axes[1].set_title('Gender')\n",
    "    axes[1].bar(counts.index.astype(str), counts.values, color=['skyblue', 'skyblue'], edgecolor='black')\n",
    "    axes[1].set_xticks(range(len(counts.index)))\n",
    "    axes[1].set_xticklabels(['Male', 'Female'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[1].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Age Distribution & Box\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    fig.suptitle('Study Subjects - Age Distribution', fontsize=18)\n",
    "\n",
    "    axes[0].hist(subjects_df['age'], bins=15, color='skyblue', edgecolor='black')\n",
    "\n",
    "    axes[1].set_xticks([0])\n",
    "    box = axes[1].boxplot(subjects_df['age'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9095073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for EEG Preprocessing Results\n",
    "#\n",
    "\n",
    "def eeg_preprocess_results_plot(results_df):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "    fig.suptitle('EEG Preprocessing Metrics - All Subjects', fontsize=18)\n",
    "\n",
    "    # Quality Warning\n",
    "    counts = results_df['EEG_preprocessing_quality_warning'].value_counts().reindex([True, False], fill_value=0)\n",
    "    axes[0].set_title('Overall Quality Warning Count')\n",
    "    axes[0].bar(counts.index.astype(str), counts.values, color=['salmon', 'lightgreen'], edgecolor='black')\n",
    "    axes[0].set_xticks(range(len(counts.index)))\n",
    "    axes[0].set_xticklabels(['Yes', 'No'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[0].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    # # Channels count\n",
    "    # counts = results_df['channel_count'].value_counts()\n",
    "    # axes[1].set_title('Channels Count')\n",
    "    # axes[1].bar(counts.index.astype(str), counts.values, color=['skyblue'], edgecolor='black')\n",
    "\n",
    "    # ICA Rejection Level\n",
    "    axes[1].set_title('ICA - ICs Rejection Level')\n",
    "    box = axes[1].boxplot(results_df['ICA_rejection_level'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # Epoch Rejection Level\n",
    "    axes[2].set_title('Epoch Rejection Level')\n",
    "    box = axes[2].boxplot(results_df['epoch_rejection_level'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "    # axes[2].set_xlabel('Epoch Rejection Level')\n",
    "    # axes[2].set_ylabel('Number of Subjects')\n",
    "    # axes[2].hist(results_df['epoch_rejection_level'], bins=10, color='skyblue', edgecolor='black')\n",
    "    # nonzero_epoch_rejection = results_df['epoch_rejection_level'][results_df['epoch_rejection_level'] > 0]\n",
    "    # axes[2].hist(nonzero_epoch_rejection, bins=15, color='salmon', edgecolor='black', alpha=0.7)\n",
    "    # for bar in axes[2].patches:\n",
    "    #     bar.set_width(bar.get_width() * 0.8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d485d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for EEG SpecParam Results\n",
    "#\n",
    "\n",
    "def eeg_specparam_results_plot(results_df):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "    fig.suptitle('EEG SpecParam Fit Metrics - All Subjects', fontsize=18)\n",
    "\n",
    "    # Quality Warning\n",
    "    counts = results_df['chn_SPM_fit_quality_warning'].value_counts().reindex([True, False], fill_value=0)\n",
    "    axes[0].set_title('Overall Quality Warning Count')\n",
    "    axes[0].bar(counts.index.astype(str), counts.values, color=['salmon', 'lightgreen'], edgecolor='black')\n",
    "    \n",
    "    axes[0].set_xticks(range(len(counts.index)))\n",
    "    axes[0].set_xticklabels(['Yes', 'No'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[0].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    # Error Mean\n",
    "    axes[1].set_title('Error Mean')\n",
    "    box = axes[1].boxplot(results_df['chn_error_mean'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # R-Squared Mean\n",
    "    axes[2].set_title('R2 Mean')\n",
    "    box = axes[2].boxplot(results_df['chn_r2_mean'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Number of flagged channels\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(3, 4))\n",
    "    # fig.suptitle('EEG SpecParam Fit Metrics - Flagged Channels', fontsize=18)\n",
    "    flagged_counts = results_df['chn_flagged_channels'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    axes.set_title('Flagged Channels Count')\n",
    "    box = axes.boxplot(flagged_counts, patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='salmon')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28feac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Aperiodic Features Spread\n",
    "#\n",
    "\n",
    "def aperiodic_features_plot(results_df, level):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    fig.suptitle(f'Aperiodic Features - {level}', fontsize=18)\n",
    "\n",
    "    # Offset\n",
    "    axes[0].set_title('Offset')\n",
    "    box = axes[0].boxplot(results_df['offset'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # Exponent\n",
    "    axes[1].set_title('Exponent')\n",
    "    box = axes[1].boxplot(results_df['exponent'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Periodic Features Spread\n",
    "#\n",
    "\n",
    "def periodic_features_plot(results_df, level):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "    fig.suptitle(f'Periodic Features - {level}', fontsize=18)\n",
    "\n",
    "    # CF\n",
    "    axes[0].set_title('CF_0')\n",
    "    box = axes[0].boxplot(results_df['cf_0'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # PW\n",
    "    axes[1].set_title('PW_0')\n",
    "    box = axes[1].boxplot(results_df['pw_0'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # BW\n",
    "    axes[2].set_title('BW_0')\n",
    "    box = axes[2].boxplot(results_df['bw_0'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Aperiodic Peaks Count \n",
    "#\n",
    "\n",
    "def periodic_peaks_plot(results_df):\n",
    "\n",
    "    regions_df = results_df[results_df['channel'].isnull()].copy()\n",
    "    cf_cols = [col for col in regions_df.columns if col.startswith('cf_')]\n",
    "    regions_df['num_periodic_cf'] = regions_df[cf_cols].notnull().sum(axis=1)\n",
    "    \n",
    "    channels_df = results_df[results_df['region'].isnull()].copy()\n",
    "    cf_cols = [col for col in channels_df.columns if col.startswith('cf_')]\n",
    "    channels_df['num_periodic_cf'] = channels_df[cf_cols].notnull().sum(axis=1)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    fig.suptitle(f'Periodic Peaks Count', fontsize=18)\n",
    "\n",
    "    # Region\n",
    "    axes[0].set_title('Regions')\n",
    "    box = axes[0].boxplot(regions_df['num_periodic_cf'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # Channel\n",
    "    axes[1].set_title('Channels')\n",
    "    box = axes[1].boxplot(channels_df['num_periodic_cf'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b0e42",
   "metadata": {},
   "source": [
    "## Functions - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using a Custom Transformer class\n",
    "#\n",
    "\n",
    "class FeatureSelection(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, features_detail_level='default', selected_features='default'):\n",
    "        # Parameters for the selection\n",
    "        self.features_detail_level = features_detail_level\n",
    "        self.selected_features = selected_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_temp_df = X.copy()\n",
    "        else:\n",
    "            raise ValueError(\"X must be a pandas DataFrame for feature selection.\")\n",
    "                \n",
    "        # Filter out features according to detail level, ie region or channel\n",
    "        drop_cols =[]\n",
    "        if self.features_detail_level == 'region':\n",
    "            drop_cols = drop_cols + [col for col in X_temp_df.columns if col.startswith('channel')]\n",
    "        elif self.features_detail_level == 'channel':\n",
    "            drop_cols = drop_cols +[col for col in X_temp_df.columns if col.startswith('region')]\n",
    "        else:\n",
    "            raise ValueError(f'Detail of {self.features_detail_level} is not region or channel')\n",
    "        X_temp_df = X_temp_df.drop(columns=drop_cols, errors='ignore')\n",
    "        \n",
    "        # Only retain columns whose names contain any of the selected features\n",
    "        X_temp_df = X_temp_df[[col for col in X_temp_df.columns if any(feat in col for feat in self.selected_features)]]\n",
    "       \n",
    "        self.selected_features_ = list(X_temp_df)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_temp_df = X.copy()\n",
    "        else:\n",
    "            raise ValueError(\"X must be a pandas DataFrame for feature selection.\")\n",
    "        \n",
    "        # Apply feature selection\n",
    "        return X[self.selected_features_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep Pipeline\n",
    "#\n",
    "\n",
    "def data_prep_pipeline():\n",
    "\n",
    "    # Sub pipeline for numerical and categorical transformations\n",
    "    num_pipeline = Pipeline([\n",
    "        ('impute', SimpleImputer(keep_empty_features=True, strategy='constant', fill_value=0)),\n",
    "        # ('scale_num', RobustScaler())\n",
    "        ('scale_num', RobustScaler(quantile_range=(10.0, 90.0)))\n",
    "        ])\n",
    "    cat_pipeline = Pipeline([\n",
    "        # (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        # (\"encode_cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "        ('encode_cat', OneHotEncoder(drop='first', handle_unknown='infrequent_if_exist'))\n",
    "        ])\n",
    "    cols_transform = ColumnTransformer([\n",
    "        ('numeric', num_pipeline, make_column_selector(dtype_include=['float64', 'int64'])),\n",
    "        ('categorical', cat_pipeline, make_column_selector(dtype_include='object'))\n",
    "    ])\n",
    "\n",
    "    # Setup & train/fit the overall pipeline\n",
    "    features_prep_pipeline = Pipeline([\n",
    "        ('data_preprocess', cols_transform)\n",
    "        ])  \n",
    "    \n",
    "    return features_prep_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "#\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, verbose=True):\n",
    "\n",
    "    # Run predictions\n",
    "    start_time = time.perf_counter()\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_probs = model.predict_proba(X_test)\n",
    "    duration = time.perf_counter() - start_time\n",
    "\n",
    "    # Calculate Metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    recall = metrics.recall_score(y_true=y_test, y_pred=y_pred, pos_label=1)\n",
    "    precision = metrics.precision_score(y_true=y_test, y_pred=y_pred, pos_label=1)\n",
    "    f1_score = metrics.f1_score(y_true=y_test, y_pred=y_pred, pos_label=1)\n",
    "    specificity = tn / (tn + fp)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    # Print Metrics\n",
    "    if verbose:\n",
    "        print(f'----Evaluation Result for: {model.model_name} -------')\n",
    "        print(f'Recall (Sensitivity, TP Rate): {recall:.4f}')\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "        print(f'F1 Score {f1_score:.4f}')\n",
    "        print(f'Specificity (1 - Fall-Out): {specificity:.4f}')\n",
    "        print(f'MCC: {mcc:.4f}')\n",
    "        print('-----------')\n",
    "        print(f'Accuracy: {metrics.accuracy_score(y_true=y_test, y_pred=y_pred):.4f}')\n",
    "        print(f'Fall Out (FPR): {fp / (fp + tn):.4f}')\n",
    "        print(f'Hamming Loss {metrics.hamming_loss(y_true=y_test, y_pred=y_pred):.4f}')\n",
    "        roc_auc_score = metrics.roc_auc_score(y_true=y_test, y_score=y_probs[:,1])\n",
    "        print(f'ROC-AUC Score {roc_auc_score:.4f}')\n",
    "        gini_score = 2 * roc_auc_score - 1\n",
    "        print(f'Gini Index: {gini_score:.4f}')\n",
    "        print('-----------')\n",
    "\n",
    "    # Plot Confusion Matrix & ROC Curve\n",
    "    if verbose:\n",
    "        plt.style.use('default')\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,6))\n",
    "        fig.suptitle(f'Model Prediction Evaluation', fontsize=20)\n",
    "\n",
    "        axes[0].set_title('Confusion Matrix')    \n",
    "        class_labels = model.classes_\n",
    "        ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels).plot(ax=axes[0])\n",
    "        axes[1].set_title('ROC Curve')\n",
    "        # roc_display = RocCurveDisplay.from_estimator(model, X_test, y_test, ax=axes[1], pos_label=1)\n",
    "        RocCurveDisplay.from_predictions(y_test, y_probs[:,1], ax=axes[1], pos_label=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.style.use('ggplot')\n",
    "\n",
    "    # Create Predications df With Confidences\n",
    "    predicted_confidence = [y_probs[i, pred] for i, pred in enumerate(y_pred)]\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'Ground_Truth': y_test,\n",
    "        'Prediction': y_pred,\n",
    "        'Confidence': predicted_confidence\n",
    "        })\n",
    "    # Highlight Mismatches\n",
    "    if verbose:\n",
    "        print('Mismatches')\n",
    "        mismatches = predictions_df[predictions_df['Prediction'] != predictions_df['Ground_Truth']]\n",
    "        display(mismatches)\n",
    "\n",
    "    # Return Results\n",
    "    results = {'study': 'test_study',\n",
    "               'training_source_data_run': 'test run name',\n",
    "               'training_results_run': 'test run name',\n",
    "               'CV_search_time': 0,\n",
    "               'CV_best_parameters': '{xx}',\n",
    "               'features_detail': 'test region',\n",
    "               'features_selection': 'test list',\n",
    "               'model_name': model.model_name,\n",
    "               'prediction_time': duration,\n",
    "               'recall': recall,\n",
    "               'precision': precision,\n",
    "               'f1_score': f1_score,\n",
    "               'specificity': specificity,\n",
    "               'mcc': mcc\n",
    "               }\n",
    "    \n",
    "    return results, predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6189d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Importance / Contribution - SHAP\n",
    "#\n",
    "\n",
    "def contribution_shap(model, X_train, X_test):\n",
    "    model_classifier = model.steps[-1][1] \n",
    "    preprocessing_steps = list(model.named_steps.items())[:-1] \n",
    "    preprocessing_pipeline = Pipeline(preprocessing_steps)\n",
    "\n",
    "    X_train_transformed = preprocessing_pipeline.transform(X_train)\n",
    "    X_test_transformed = preprocessing_pipeline.transform(X_test)\n",
    "    feature_names = preprocessing_pipeline.named_steps['data_preprocess'].get_feature_names_out()\n",
    "    print(f'Feature Names: {len(feature_names)}')\n",
    "    # print(feature_names)\n",
    "\n",
    "    # Create Explainer with background data \n",
    "    def model_predict(X):\n",
    "        return model_classifier.predict_proba(X)[:, 1] \n",
    "\n",
    "    # Calc SHAP values\n",
    "    background = X_train_transformed[np.random.choice(X_train_transformed.shape[0], 100, replace=False)]\n",
    "    explainer = shap.KernelExplainer(model_predict, background)\n",
    "    shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "    # Get mean absolute SHAP values for global importance & % additional contribution\n",
    "    global_importance = np.abs(shap_values).mean(axis=0)\n",
    "    importance_percentages = (global_importance / global_importance.sum()) * 100\n",
    "    shap_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance_%': importance_percentages\n",
    "    }).sort_values(by='importance_%', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Plot the Top 25\n",
    "    print('SHAP Values Importance')\n",
    "    print(shap_importance_df.shape)\n",
    "    display(shap_importance_df.head())\n",
    "\n",
    "    importance_df = shap_importance_df.head(25)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(importance_df['feature'], importance_df['importance_%'], color='skyblue')\n",
    "    plt.xlabel('Importance %')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances (Sorted)')\n",
    "    plt.gca().invert_yaxis() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475b484",
   "metadata": {},
   "source": [
    "## Functions - Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search For A Model\n",
    "#\n",
    "\n",
    "def run_grid_search(model_pipeline, grid_params, X_train, y_train, scoring, verbose=False):\n",
    "\n",
    "    # # Straight k-fold cross-validation\n",
    "    # grid_search = GridSearchCV(\n",
    "    #     model_pipeline, grid_params, cv=5, n_jobs=-1,\n",
    "    #     scoring='precision'\n",
    "    #     )\n",
    "\n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(\n",
    "        model_pipeline, grid_params, cv=skf, n_jobs=-1,\n",
    "        # scoring='precision'\n",
    "        # scoring='f1'\n",
    "        # scoring='roc_auc'\n",
    "        # scoring='matthews_corrcoef'\n",
    "        scoring = scoring\n",
    "        )\n",
    "\n",
    "    # Grid search run\n",
    "    start_time = time.perf_counter()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    duration = time.perf_counter() - start_time\n",
    "\n",
    "    # Model Details\n",
    "    if verbose:\n",
    "        print('Model Training Pipeline Steps')\n",
    "        for name, step in model_pipeline.named_steps.items():\n",
    "            print(f\"- {name}: {step}\")\n",
    "        print('All Pipeline Parameters:')\n",
    "        for param, value in model_pipeline.get_params().items():\n",
    "            print(f\"- {param}: {value}\")\n",
    "\n",
    "    # Grid Search Results\n",
    "    if verbose:\n",
    "        print('\\nGrid Search Results')\n",
    "        all_search_results = pd.DataFrame(grid_search.cv_results_)\n",
    "        print(f\"Score: {grid_search.best_score_:.4f}. Mean: {np.mean(all_search_results['mean_test_score']):.4f} and STD {np.std(all_search_results['mean_test_score']):.4f}\")\n",
    "        print(f'Search Took: {duration:.2f} seconds')\n",
    "        print('-----------------')\n",
    "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        print(f'Best C-V Score: {grid_search.best_score_}')\n",
    "        top_n = 10\n",
    "        print(f'Combinations Searched: {len(all_search_results)}')\n",
    "        print(f\"Top {top_n} out of {len(all_search_results)} combinations:\")\n",
    "        display(all_search_results[['rank_test_score', 'mean_test_score', 'mean_fit_time', 'params', 'param_features_selection__features_detail_level', 'param_features_selection__selected_features']].sort_values(by='rank_test_score').head(top_n))\n",
    "        print('-----------------')\n",
    "        print(f'Best Model: \\n{grid_search.best_estimator_}')\n",
    "\n",
    "    return duration, grid_search\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model Training Function\n",
    "#\n",
    "\n",
    "def model_train_RandForest(X_train, y_train, feature_selector=None, cols_transform=None, detail_level=None, features_selected=None,verbose=False):\n",
    "\n",
    "    model_name = 'RandomForest_v1'\n",
    "\n",
    "    # Use the data pipeline in the search\n",
    "    if feature_selector:\n",
    "        model_pipeline = Pipeline([\n",
    "            ('features_selection', feature_selector),\n",
    "            ('data_preprocess', cols_transform),\n",
    "            ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1, verbose=False))\n",
    "            ])\n",
    "\n",
    "        grid_params = {\n",
    "            'features_selection__features_detail_level': detail_level,\n",
    "            'features_selection__selected_features': features_selected,\n",
    "            'classifier__criterion': ['gini', 'entropy', 'log_loss'],     # Default gini. Tree split evaluation function\n",
    "            'classifier__n_estimators': [100, 150],                       # Default 100. Number of trees\n",
    "            'classifier__max_depth': [3, 10, 15],                         # Default none, unlimited ... but don't want to overfit\n",
    "            # 'classifier__max_features': [0.8, 2],                       # Default is sqrt\n",
    "            'classifier__max_leaf_nodes': [50, None],                     # Default none, unlimited\n",
    "            # 'randomforestclassifier__min_samples_split': [2, 5],\n",
    "            # 'classifier__class_weight': [None, 'balanced']              # Balanced gives more importance to minority classes ... ?? Improves recall at the expense of precision\n",
    "            }\n",
    "    else:\n",
    "        model_pipeline = Pipeline([\n",
    "            ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1, verbose=False))\n",
    "            ])\n",
    "\n",
    "        grid_params = {\n",
    "            'classifier__criterion': ['gini', 'entropy', 'log_loss'],     # Default gini. Tree split evaluation function\n",
    "            'classifier__n_estimators': [100, 150],                       # Default 100. Number of trees\n",
    "            'classifier__max_depth': [3, 10, 15],                         # Default none, unlimited ... but don't want to overfit\n",
    "            # 'classifier__max_features': [0.8, 2],                       # Default is sqrt\n",
    "            'classifier__max_leaf_nodes': [50, None],                     # Default none, unlimited\n",
    "            # 'randomforestclassifier__min_samples_split': [2, 5],\n",
    "            # 'classifier__class_weight': [None, 'balanced']              # Balanced gives more importance to minority classes ... ?? Improves recall at the expense of precision\n",
    "            }\n",
    "    \n",
    "    # Run Grid Search\n",
    "    duration, grid_search = run_grid_search(model_pipeline, grid_params, X_train, y_train, scoring='matthews_corrcoef', verbose=verbose)\n",
    "\n",
    "\n",
    "    # Retain the best model & save it, as well as the grid search\n",
    "    model = grid_search.best_estimator_\n",
    "    model.model_name = model_name\n",
    "\n",
    "    return model, duration, grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd345fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model Training\n",
    "#\n",
    "\n",
    "def model_train_LogReg(X_train, y_train, feature_selector=None, cols_transform=None, detail_level=None, features_selected=None,verbose=True):\n",
    "\n",
    "    model_name = 'LogisticRegression_v1'\n",
    "\n",
    "    # Use the data pipeline in the search\n",
    "    if feature_selector:\n",
    "        model_pipeline = Pipeline([\n",
    "            ('features_selection', feature_selector),\n",
    "            ('data_preprocess', cols_transform),\n",
    "            ('classifier', LogisticRegression(random_state=42))\n",
    "            ])\n",
    "        grid_params = {\n",
    "            'features_selection__features_detail_level': detail_level,\n",
    "            'features_selection__selected_features': features_selected,\n",
    "            'classifier__solver': ['saga','liblinear', 'lbfgs'],          # Default is lbfgs. Saga with L1 or l2. Large dataset. liblinear small datasets, binary classifications\n",
    "            'classifier__penalty': ['l1', 'l2'],                          # Types of regulaisation\n",
    "            'classifier__C': [1, 10, 100],                                # Default 1. Strength of regularisation, smaller is stronger\n",
    "            'classifier__class_weight': [None, 'balanced'],               # Default None. Balanced seems to prevent near zero True predictions\n",
    "            'classifier__max_iter': [1000, 2500, 5000]                    # Default 100. \n",
    "            }\n",
    "    else:\n",
    "        model_pipeline = Pipeline([\n",
    "        ('classifier', LogisticRegression(random_state=42))\n",
    "        ])\n",
    "        grid_params = {\n",
    "            'classifier__solver': ['saga','liblinear', 'lbfgs'],          # Default is lbfgs. Saga with L1 or l2. Large dataset. liblinear small datasets, binary classifications\n",
    "            'classifier__penalty': ['l1', 'l2'],                          # Types of regulaisation\n",
    "            'classifier__C': [1, 10, 100],                                # Default 1. Strength of regularisation, smaller is stronger\n",
    "            'classifier__class_weight': [None, 'balanced'],               # Default None. Balanced seems to prevent near zero True predictions\n",
    "            'classifier__max_iter': [1000, 2500, 5000]                    # Default 100. \n",
    "            }\n",
    "    \n",
    "    # Run Grid Search\n",
    "    duration, grid_search = run_grid_search(model_pipeline, grid_params, X_train, y_train, scoring='matthews_corrcoef', verbose=verbose)\n",
    "\n",
    "\n",
    "    # Retain the best model & save it, as well as the grid search\n",
    "    model = grid_search.best_estimator_\n",
    "    model.model_name = model_name\n",
    "\n",
    "    return model, duration, grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee56694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Classifier Training Function\n",
    "#\n",
    "\n",
    "def model_train_MLPC(X_train, y_train, feature_selector=None, cols_transform=None, detail_level=None, features_selected=None,verbose=False):\n",
    "\n",
    "    model_name = 'MLPClassifier_v1'\n",
    "\n",
    "    # Use the data pipeline in the search\n",
    "    if feature_selector:\n",
    "        model_pipeline = Pipeline([\n",
    "            ('features_selection', feature_selector),\n",
    "            ('data_preprocess', cols_transform),\n",
    "            ('classifier', MLPClassifier(random_state=42))\n",
    "            ])\n",
    "        grid_params = {\n",
    "            'features_selection__features_detail_level': detail_level,\n",
    "            'features_selection__selected_features': features_selected,\n",
    "            'classifier__hidden_layer_sizes': [(50,50), (100,50)],             # Default, single layer of 100\n",
    "            # 'classifier__hidden_layer_sizes': [(50,), (100,), (50,50)],      # Default, single layer of 100\n",
    "            'classifier__activation': ['tanh', 'relu'],                        # Default: relu\n",
    "            # 'classifier__solver': ['adam', 'lbfgs', 'sgd'],                  # Default adam\n",
    "            'classifier__solver': ['adam'],                                    # Default adam\n",
    "            'classifier__learning_rate_init': [0.00001, 0.0001, 0.001],\n",
    "            'classifier__alpha': [0.1],                                         # default L2, 0.0001,\n",
    "            # 'classifier__early_stopping': [True],\n",
    "            'classifier__batch_size': ['auto'],\n",
    "            'classifier__max_iter': [1000]                                      # Default 200\n",
    "            }\n",
    "    else:\n",
    "        model_pipeline = Pipeline([\n",
    "            ('classifier', MLPClassifier(random_state=42))\n",
    "            ])\n",
    "        grid_params = {\n",
    "            'classifier__hidden_layer_sizes': [(50,50), (100,50)],             # Default, single layer of 100\n",
    "            # 'classifier__hidden_layer_sizes': [(50,), (100,), (50,50)],      # Default, single layer of 100\n",
    "            'classifier__activation': ['tanh', 'relu'],                        # Default: relu\n",
    "            # 'classifier__solver': ['adam', 'lbfgs', 'sgd'],                  # Default adam\n",
    "            'classifier__solver': ['adam'],                                    # Default adam\n",
    "            'classifier__learning_rate_init': [0.00001, 0.0001, 0.001],\n",
    "            'classifier__alpha': [0.1],                                         # default L2, 0.0001,\n",
    "            # 'classifier__early_stopping': [True],\n",
    "            'classifier__batch_size': ['auto'],\n",
    "            'classifier__max_iter': [1000]                                      # Default 200\n",
    "            }\n",
    "    \n",
    "    # Run Grid Search\n",
    "    duration, grid_search = run_grid_search(model_pipeline, grid_params, X_train, y_train, scoring='average_precision', verbose=verbose)\n",
    "\n",
    "    # Retain the best model & save it, as well as the grid search\n",
    "    model = grid_search.best_estimator_\n",
    "    model.model_name = model_name\n",
    "\n",
    "    return model, duration, grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba6e54",
   "metadata": {},
   "source": [
    "# Run: 1. Study Load & Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a8e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study and Processing Run Details\n",
    "\n",
    "#---- Parameters --------------------------------\n",
    "# Study & Training Data\n",
    "study_name = 'IOWA_Rest'\n",
    "eeg_features_run = '1b_EEG_Features_Results_Run_20250801_full_run'\n",
    "\n",
    "# Training Run Name & Params\n",
    "run_description = 'search_all'\n",
    "extraction_params = {'features_detail_level': 'both',    # region, channel, both\n",
    "                     'subject_meta_include': True,\n",
    "                     'aperiodic_include': True,\n",
    "                     'periodic_include': True\n",
    "                    }\n",
    "model_training_params = {'EEG_features_source_run': eeg_features_run}\n",
    "test_mode = True\n",
    "#----------------------------------------------------\n",
    "\n",
    "# Get existing study details, if exists\n",
    "study_folder_path = utils.get_folder_path('Study_' + study_name)\n",
    "study_info = pd.read_pickle(study_folder_path + '/study_inf.pkl', compression='zip')\n",
    "study_subjects_df = pd.read_pickle(study_folder_path + '/study_subjects_df.pkl', compression='zip')\n",
    "\n",
    "# EEG Processing Results Data\n",
    "eeg_features_run_results_path = utils.get_folder_path(study_info['eeg_processing_results_path'] + '/' + eeg_features_run)\n",
    "eeg_features_run_details = pd.read_pickle(eeg_features_run_results_path + '/run_details.pkl', compression='zip')\n",
    "eeg_preprocessing_run = eeg_features_run_details['eeg_preprocessed_data']\n",
    "\n",
    "eeg_preprocessing_run_results_path = utils.get_folder_path(study_info['eeg_processing_results_path'] + '/' + eeg_preprocessing_run)\n",
    "eeg_preprocessed_data_path = utils.get_folder_path(eeg_preprocessing_run_results_path + '/Cleaned_files' )\n",
    "eeg_preprocessing_run_details = pd.read_pickle(eeg_preprocessing_run_results_path + '/run_details.pkl', compression='zip')\n",
    "eeg_processing_results_df = pd.read_pickle(eeg_features_run_results_path + '/eeg_processing_results_df.pkl', compression='zip')\n",
    "eeg_features_superset_df = pd.read_pickle(eeg_features_run_results_path + '/eeg_features_superset_df.pkl', compression='zip')\n",
    "eeg_features_flattened_df = pd.read_pickle(eeg_features_run_results_path + '/eeg_features_flattened_df.pkl', compression='zip')\n",
    "\n",
    "# Setup the extraction run and results folder & save params\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "run_name = f'2_Feature_Selection_Training_Run_{current_date}_{run_description}'\n",
    "run_results_path = utils.extend_folder_path(study_info['ml_training_results_path'], run_name, exists_ok=False)\n",
    "\n",
    "run_details = pd.Series({\n",
    "    'study_name': study_name,\n",
    "    'run_name': run_name,\n",
    "    'extraction_params': extraction_params,\n",
    "    'model_training_params': model_training_params\n",
    "    })\n",
    "run_details.to_pickle(run_results_path + '/run_details.pkl', compression='zip')\n",
    "\n",
    "# Set progress messages, testing\n",
    "if test_mode:\n",
    "    VERBOSE = True\n",
    "else:\n",
    "    VERBOSE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db334c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Run Details & Data Structures\n",
    "summary = f'EEG Processing Parameters'\n",
    "summary = summary + f\"\\n- Study: {study_info['study_name']} {study_info['dataset_ref']}\"\n",
    "summary = summary + f\"\\n- EEG Processing Run: {eeg_preprocessing_run_details['run_name']}\"\n",
    "summary = summary + f\"\\n-   Preprocess Params: {eeg_preprocessing_run_details['preprocess_params']}\"\n",
    "summary = summary + f\"\\n-   ICA Params: {eeg_preprocessing_run_details['artefact_params']}\"\n",
    "summary = summary + f\"\\n- EEG Features Run: {eeg_features_run}\"\n",
    "summary = summary + f\"\\n-   PSD Params: {eeg_features_run_details['psd_params']}\"\n",
    "summary = summary + f\"\\n-   SpecParam Params: {eeg_features_run_details['specparam_params']}\"\n",
    "summary = summary + f\"\\n- Features Selection Run: {run_name}\"\n",
    "summary = summary + f\"\\n-   Feature Selection Params: {run_details['extraction_params']}\"\n",
    "summary = summary + f\"\\n-   Model Training Params: {run_details['model_training_params']}\"\n",
    "\n",
    "print(f'{summary}\\n')\n",
    "\n",
    "# Processing Metrics\n",
    "print('EEG Processing Results')\n",
    "print(eeg_processing_results_df.shape)\n",
    "display(eeg_processing_results_df.head())\n",
    "\n",
    "print(f'Null Fits: {sum(eeg_processing_results_df[\"chn_null_fits\"])}')\n",
    "eeg_preprocess_results_plot(eeg_processing_results_df)\n",
    "eeg_specparam_results_plot(eeg_processing_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study Subjects Summary\n",
    "print('Study Subjects')\n",
    "print(study_subjects_df.shape)\n",
    "display(study_subjects_df.head())\n",
    "\n",
    "subject_info_plot(study_subjects_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84559552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Superset \n",
    "print('EEG Features Superset')\n",
    "print(eeg_features_superset_df.shape)\n",
    "display(eeg_features_superset_df.head())\n",
    "\n",
    "# Features Flattened \n",
    "print('EEG Features Flattened')\n",
    "print(eeg_features_flattened_df.shape)\n",
    "display(eeg_features_flattened_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - At Region & Channel Detail Level\n",
    "#\n",
    "\n",
    "regions_df = eeg_features_superset_df[eeg_features_superset_df['channel'].isnull()].copy()\n",
    "channels_df = eeg_features_superset_df[eeg_features_superset_df['region'].isnull()].copy()\n",
    "\n",
    "aperiodic_features_plot(regions_df, 'Regions')\n",
    "aperiodic_features_plot(channels_df, 'Channels')\n",
    "\n",
    "periodic_features_plot(regions_df, 'Regions')\n",
    "periodic_features_plot(channels_df, 'Channels')\n",
    "\n",
    "periodic_peaks_plot(eeg_features_superset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7963ab",
   "metadata": {},
   "source": [
    "# Run: 2. Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfa973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X features and y target\n",
    "# For Data Pipeline & ML Model Training\n",
    "#\n",
    "\n",
    "target_col_name = 'pd'\n",
    "feature_names = eeg_features_flattened_df.columns[eeg_features_flattened_df.columns != target_col_name]\n",
    "X = eeg_features_flattened_df[feature_names].copy()\n",
    "y = eeg_features_flattened_df[target_col_name].copy()\n",
    "\n",
    "# Data Split : Training & Test, 80:20. NB cross-validation will be performed using Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# split by *subjects*, not by raw rows\n",
    "# train_subj, test_subj = train_test_split(subjects, stratify=labels,\n",
    "#                                          test_size=.3, random_state=42)\n",
    "# X_train = eeg_long[eeg_long.subject_id.isin(train_subj)]\n",
    "# X_test  = eeg_long[eeg_long.subject_id.isin(test_subj)]\n",
    "# y_train = labels.loc[train_subj].values\n",
    "# y_test  = labels.loc[test_subj].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models Training & Evaluations\n",
    "#\n",
    "\n",
    "# Feature Selection Params\n",
    "if extraction_params['features_detail_level'] == 'both':\n",
    "    detail_level_params = ['region', 'channel']\n",
    "elif extraction_params['features_detail_level'] == 'region':\n",
    "    detail_level_params = ['region']\n",
    "else:\n",
    "    detail_level_params = ['channel']\n",
    "\n",
    "# Different Combinations\n",
    "features_selected = []\n",
    "features_selected += [['exp', 'offset']] if extraction_params['aperiodic_include'] else []\n",
    "features_selected += [['cf', 'pw', 'bw']] if extraction_params['periodic_include'] else []\n",
    "features_selected += [['age', 'gender']] if extraction_params['subject_meta_include'] else []\n",
    "# ALL Features\n",
    "# features_selected = [['exp', 'offset', 'cf', 'pw', 'bw']]\n",
    "\n",
    "# Loop through all models to evaluate\n",
    "#\n",
    "models_results = []\n",
    "function_map = {'Random_Forest': model_train_RandForest,\n",
    "                'Logistic_Regression': model_train_LogReg,\n",
    "                'MLP_Classifier': model_train_MLPC\n",
    "                }\n",
    "models_list = ['Random_Forest', 'Logistic_Regression', 'MLP_Classifier']\n",
    "\n",
    "for model_name in models_list:\n",
    "    print(f'---- Model Training: {model_name} -------')\n",
    "    model_train_func = function_map[model_name]\n",
    "    model, search_duration, grid_search = model_train_func(X_train, y_train, FeatureSelection(), data_prep_pipeline(), \n",
    "                                                            detail_level=detail_level_params, features_selected=features_selected,\n",
    "                                                            verbose=False)\n",
    "    \n",
    "    # Evaluate Model & Features Importance (SHAP)\n",
    "    eval_results, predictions_df = evaluate_model(model, X_test, y_test)\n",
    "    contribution_shap(model, X_train, X_test)\n",
    "\n",
    "    # Append Metrics\n",
    "    eval_results['study'] = study_name\n",
    "    eval_results['training_source_data_run'] = eeg_features_run\n",
    "    eval_results['training_results_run'] = run_name\n",
    "    eval_results['CV_search_time'] = search_duration\n",
    "    best_params = grid_search.best_params_\n",
    "    eval_results['CV_best_parameters'] = best_params\n",
    "    eval_results['features_detail'] = best_params.get('features_selection__features_detail_level')\n",
    "    eval_results['features_selection'] = best_params.get('features_selection__selected_features')\n",
    "    models_results.append(eval_results)\n",
    "    print(eval_results)\n",
    "\n",
    "    # Save Model & Grid Search\n",
    "    cloudpickle.dump(grid_search, open(run_results_path + '/' + f'grid_search_{model_name}.pkl', 'wb'))\n",
    "    cloudpickle.dump(model, open(run_results_path + '/' + f'model_{model_name}.pkl', 'wb'))\n",
    "    \n",
    "# Save All Models Evaluation df\n",
    "print(f'---- Model Training Finished & Saved -------')\n",
    "models_results_df = pd.DataFrame(models_results)\n",
    "display(models_results_df)\n",
    "models_results_df.to_pickle(run_results_path + '/models_results_df.pkl', compression='zip') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_ml_pipeline_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
