{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ff5010",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b87c4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aba81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import warnings\n",
    "from typing import Literal\n",
    "\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Custom Functions\n",
    "sys.path.append(os.path.abspath('../Notebooks/Utilities')) \n",
    "import cust_utilities as utils\n",
    "\n",
    "# Maths, Pandas etc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sci\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ML Prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "# ML Training\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e0caeb",
   "metadata": {},
   "source": [
    "# Features DF Tidy Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5f9672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Processing Parameters\n",
      "- Study: IOWA_Simon ds004580-1.0.0\n",
      "- EEG Processing Run: 1a_EEG_Preprocessing_Run_20250724_full_ica\n",
      "-   Preprocess Params: {'band_pass_lf': 1, 'band_pass_hf': 100, 'band_pass_method': 'iir', 'phase': 'zero', 'linear_detrend': 'linear', 'channel_referencing': 'average'}\n",
      "-   ICA Params: {'ica_method': 'infomax', 'ICA_rejection_threshold': 0.8}\n",
      "- EEG Features Run: 1b_EEG_Features_Results_Run_20250726_full_run\n",
      "-   PSD Params: {'method': 'welch', 'fmin': 1, 'fmax': 100, 'exclude': []}\n",
      "-   SpecParam Params: {'peak_width_limits': [1, 12], 'max_n_peaks': 6, 'min_peak_height': 0.1, 'peak_threshold': 2.0, 'aperiodic_mode': 'fixed', 'fit_window': [2, 40], 'fit_error_threshold': 0.1, 'fit_r2_threshold': 0.9}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Original Data\n",
    "\n",
    "#---- Parameters --------------------------------\n",
    "# Study & Processing Run Details\n",
    "study_name = 'IOWA_Simon'\n",
    "eeg_features_run = '1b_EEG_Features_Results_Run_20250726_full_run'\n",
    "\n",
    "#----------------------------------------------------\n",
    "\n",
    "# Get existing study details, if exists\n",
    "study_folder_path = utils.get_folder_path('Study_' + study_name)\n",
    "study_info = pd.read_pickle(study_folder_path + '/study_inf.pkl', compression='zip')\n",
    "study_subjects_df = pd.read_pickle(study_folder_path + '/study_subjects_df.pkl', compression='zip')\n",
    "\n",
    "# Processing Results Data\n",
    "eeg_features_run_results_path = utils.get_folder_path(study_info['eeg_processing_results_path'] + '/' + eeg_features_run)\n",
    "eeg_features_run_details = pd.read_pickle(eeg_features_run_results_path + '/run_details.pkl', compression='zip')\n",
    "eeg_preprocessing_run = eeg_features_run_details['eeg_preprocessed_data']\n",
    "\n",
    "eeg_preprocessing_run_results_path = utils.get_folder_path(study_info['eeg_processing_results_path'] + '/' + eeg_preprocessing_run)\n",
    "eeg_preprocessed_data_path = utils.get_folder_path(eeg_preprocessing_run_results_path + '/Cleaned_files' )\n",
    "eeg_preprocessing_run_details = pd.read_pickle(eeg_preprocessing_run_results_path + '/run_details.pkl', compression='zip')\n",
    "eeg_processing_results_df = pd.read_pickle(eeg_features_run_results_path + '/eeg_processing_results_df.pkl', compression='zip')\n",
    "eeg_features_superset_df = pd.read_pickle(eeg_features_run_results_path + '/eeg_features_superset_df.pkl', compression='zip')\n",
    "\n",
    "# Processing Run Details & Data Structures\n",
    "summary = f'EEG Processing Parameters'\n",
    "summary = summary + f\"\\n- Study: {study_info['study_name']} {study_info['dataset_ref']}\"\n",
    "summary = summary + f\"\\n- EEG Processing Run: {eeg_preprocessing_run_details['run_name']}\"\n",
    "summary = summary + f\"\\n-   Preprocess Params: {eeg_preprocessing_run_details['preprocess_params']}\"\n",
    "summary = summary + f\"\\n-   ICA Params: {eeg_preprocessing_run_details['artefact_params']}\"\n",
    "summary = summary + f\"\\n- EEG Features Run: {eeg_features_run}\"\n",
    "summary = summary + f\"\\n-   PSD Params: {eeg_features_run_details['psd_params']}\"\n",
    "summary = summary + f\"\\n-   SpecParam Params: {eeg_features_run_details['specparam_params']}\"\n",
    "print(f'{summary}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "018c906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp to Amend the Features Superset df with Regions / Channels separate\n",
    "\n",
    "# TODO: Amend EEG Extract to do this directly\n",
    "\n",
    "valid_regions = ['frontal', 'central', 'posterior']\n",
    "\n",
    "eeg_features_superset_df['region'] = eeg_features_superset_df['channel'].where(\n",
    "    eeg_features_superset_df['channel'].isin(valid_regions), np.nan)\n",
    "eeg_features_superset_df.loc[eeg_features_superset_df['channel'].isin(valid_regions), 'channel'] = np.nan\n",
    "cols = list(eeg_features_superset_df.columns)\n",
    "cols.insert(cols.index('subject_id') + 1, cols.pop(cols.index('region')))\n",
    "eeg_features_superset_df = eeg_features_superset_df[cols]\n",
    "\n",
    "# Save it to temp df alongside original\n",
    "eeg_features_superset_df.to_pickle(eeg_features_run_results_path + '/temp_eeg_features_superset_df.pkl', compression='zip') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c146a9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Flattened Features DataFrame\n",
      "(147, 1478)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>pd</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>region_frontal_offset</th>\n",
       "      <th>region_frontal_exponent</th>\n",
       "      <th>region_frontal_cf_0</th>\n",
       "      <th>region_frontal_pw_0</th>\n",
       "      <th>region_frontal_bw_0</th>\n",
       "      <th>region_frontal_cf_1</th>\n",
       "      <th>...</th>\n",
       "      <th>channel_Iz_pw_3</th>\n",
       "      <th>channel_Iz_bw_3</th>\n",
       "      <th>channel_Iz_cf_4</th>\n",
       "      <th>channel_Iz_pw_4</th>\n",
       "      <th>channel_Iz_bw_4</th>\n",
       "      <th>channel_Iz_cf_5</th>\n",
       "      <th>channel_Iz_pw_5</th>\n",
       "      <th>channel_Iz_bw_5</th>\n",
       "      <th>channel_Iz_error</th>\n",
       "      <th>channel_Iz_r_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-001</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>M</td>\n",
       "      <td>-11.884520</td>\n",
       "      <td>0.826830</td>\n",
       "      <td>6.358789</td>\n",
       "      <td>0.546284</td>\n",
       "      <td>3.421636</td>\n",
       "      <td>10.805299</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>-10.710919</td>\n",
       "      <td>1.458288</td>\n",
       "      <td>6.640354</td>\n",
       "      <td>0.606718</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.665970</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-003</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>F</td>\n",
       "      <td>-11.275927</td>\n",
       "      <td>1.145069</td>\n",
       "      <td>11.154159</td>\n",
       "      <td>0.845334</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-004</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>M</td>\n",
       "      <td>-11.231566</td>\n",
       "      <td>1.410881</td>\n",
       "      <td>6.126451</td>\n",
       "      <td>0.855957</td>\n",
       "      <td>3.450809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-005</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>-12.182214</td>\n",
       "      <td>0.317367</td>\n",
       "      <td>6.138914</td>\n",
       "      <td>0.308579</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.773196</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1478 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id  pd  age gender  region_frontal_offset  region_frontal_exponent  \\\n",
       "0    sub-001   1   80      M             -11.884520                 0.826830   \n",
       "1    sub-002   1   81      M             -10.710919                 1.458288   \n",
       "2    sub-003   1   68      F             -11.275927                 1.145069   \n",
       "3    sub-004   1   80      M             -11.231566                 1.410881   \n",
       "4    sub-005   1   56      M             -12.182214                 0.317367   \n",
       "\n",
       "   region_frontal_cf_0  region_frontal_pw_0  region_frontal_bw_0  \\\n",
       "0             6.358789             0.546284             3.421636   \n",
       "1             6.640354             0.606718             2.000000   \n",
       "2            11.154159             0.845334            12.000000   \n",
       "3             6.126451             0.855957             3.450809   \n",
       "4             6.138914             0.308579             2.000000   \n",
       "\n",
       "   region_frontal_cf_1  ...  channel_Iz_pw_3  channel_Iz_bw_3  \\\n",
       "0            10.805299  ...              NaN              NaN   \n",
       "1            11.665970  ...              NaN              NaN   \n",
       "2                  NaN  ...              NaN              NaN   \n",
       "3                  NaN  ...              NaN              NaN   \n",
       "4            12.773196  ...              NaN              NaN   \n",
       "\n",
       "   channel_Iz_cf_4  channel_Iz_pw_4  channel_Iz_bw_4  channel_Iz_cf_5  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   channel_Iz_pw_5  channel_Iz_bw_5  channel_Iz_error  channel_Iz_r_squared  \n",
       "0              NaN              NaN               NaN                   NaN  \n",
       "1              NaN              NaN               NaN                   NaN  \n",
       "2              NaN              NaN               NaN                   NaN  \n",
       "3              NaN              NaN               NaN                   NaN  \n",
       "4              NaN              NaN               NaN                   NaN  \n",
       "\n",
       "[5 rows x 1478 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Temp to generate a flattened combined subjects df and features df\n",
    "# So one row per subject with several hundred features\n",
    "\n",
    "# TODO: Put at the end of the EEG extract to generate store initially\n",
    "\n",
    "def combine_subjects_features(subjects_df, features_df):\n",
    "    non_feature_cols = ['subject_id', 'region', 'channel']\n",
    "\n",
    "    subjects_features = []\n",
    "    subjects = subjects_df['subject_id'].unique()\n",
    "    if 'study_name' in subjects_df.columns:\n",
    "        subjects_df = subjects_df.drop(columns=['study_name'])\n",
    "\n",
    "    for subj_id in subjects:\n",
    "        subj_meta_dict = subjects_df.loc[subjects_df['subject_id'] == subj_id].iloc[0].to_dict()\n",
    "        subj_features_df = features_df[features_df['subject_id'] == subj_id]\n",
    "        if subj_features_df.empty:\n",
    "            continue\n",
    "        \n",
    "        # Subject ID & Meta data\n",
    "        row_dict = {'subject_id': subj_id}\n",
    "        row_dict.update(subj_meta_dict)\n",
    "\n",
    "        # Flattened Region & Channel data\n",
    "        for _, next_row in subj_features_df.iterrows():\n",
    "            region = next_row['region']\n",
    "            channel = next_row['channel']\n",
    "            prefix = f'region_{region}_' if pd.notna(region) else f'channel_{channel}_'\n",
    "            for col in next_row.index:\n",
    "                if col in non_feature_cols:\n",
    "                    continue\n",
    "                row_dict[f'{prefix}{col}'] = next_row[col]\n",
    "\n",
    "        subjects_features.append(row_dict)\n",
    "    \n",
    "    combined_df = pd.DataFrame(subjects_features)\n",
    "    return combined_df\n",
    "\n",
    "eeg_features_flattened_df = combine_subjects_features(study_subjects_df, eeg_features_superset_df)\n",
    "print('Combined Flattened Features DataFrame')\n",
    "print(eeg_features_flattened_df.shape)\n",
    "display(eeg_features_flattened_df.head())\n",
    "\n",
    "# Save alongside original\n",
    "eeg_features_flattened_df.to_pickle(eeg_features_run_results_path + '/eeg_features_flattened_df.pkl', compression='zip') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_ml_pipeline_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
