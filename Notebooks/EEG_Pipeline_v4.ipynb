{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc227fa6",
   "metadata": {},
   "source": [
    "# OO Based Approach\n",
    "\n",
    "https://www.perplexity.ai/search/what-is-the-best-practice-for-GsIM4MKiSryinGQldzwVug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52027ddf",
   "metadata": {},
   "source": [
    "# EEG Dataset Processing Pipeline\n",
    "\n",
    "Scope:\n",
    "- Process a raw EEG dataset \n",
    "- Dataset containing the results of an EEG study on multiple subjects\n",
    "- Dataset that has been downloaded from OpenNeuro, and structured as per the BIDS standard, and in EEGLab '.set' format\n",
    "\n",
    "The Pipeline Stages (For each subject in an EEG study dataset):\n",
    "- EEG Dataset Load - Get the raw source EEG signal data\n",
    "- EEG Preprocessing - Execute filtering etc of the raw EEG time series data\n",
    "- Power Spectra Calculate - Calculate the power spectra, for all channels recorded\n",
    "- Spectral Parameterisation - Determine the best fitting Aperiodic and Periodic components\n",
    "- Features Set - Collate the subject and EEG data into a features set, Pandas Dataframe\n",
    "- Save Features Set - Save study and subject meta data and the feature set for separate ML use \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04eb49d",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "General dependencies:\n",
    "- python = 3.11.13\n",
    "- numpy = 2.0.2\n",
    "- scipy = 1.15.3\n",
    "- pandas = 2.2.3\n",
    "- matplotlib = 3.10.3\n",
    "\n",
    "ML dependencies:\n",
    "- scikit-learn = 1.6.1\n",
    "\n",
    "EEG specific dependencies:\n",
    "- mne = 1.9.0\n",
    "- specparam = 2.0.0rc3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd74011",
   "metadata": {},
   "source": [
    "## Python-MNE\n",
    "\n",
    "Used for Import:\n",
    "- MNE-Python: https://mne.tools/stable/index.html\n",
    "- The Brain Imaging Data Structure (BIDS): https://bids.neuroimaging.io\n",
    "\n",
    "Used for Power Spectrum Calculate\n",
    "- MNE vs NeuroDSP: https://www.perplexity.ai/search/using-python-which-package-is-zOoiPqUvTnKbO.QfgmPsJQ\n",
    "\n",
    "Formats:\n",
    "- Assumes OpenNeuro, BIDS compliant datasets manually downloaded into the defined folders structure\n",
    "- Assumes EEGLab '.set' format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38e8e9",
   "metadata": {},
   "source": [
    "## Spectral Parameterisation\n",
    "\n",
    "Spectral Parameterisation:\n",
    "- The Aperiodic Methods project - Documentation: https://aperiodicmethods.github.io/docs/index.html and Repo: in https://github.com/AperiodicMethods/AperiodicMethods\n",
    "- And cite: https://www.biorxiv.org/content/10.1101/2024.09.15.613114v1\n",
    "\n",
    "Documentation:\n",
    "- SpecParam: https://specparam-tools.github.io and https://github.com/fooof-tools\n",
    "- FOOOF: https://fooof-tools.github.io/fooof/ and https://github.com/fooof-tools/fooof\n",
    "\n",
    "FOOOF vs SpecPram:\n",
    "- FOOOF: More stable and used but deprecated\n",
    "- SpecParam: Release candidate but some improved model/fit selection: https://pmc.ncbi.nlm.nih.gov/articles/PMC11326208/\n",
    "- Summary: https://www.perplexity.ai/search/using-python-which-package-is-M7kzhERoTLuCrIKbXxN9sQ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623d60e",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8d0809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: specparam in /opt/miniconda3/envs/eeg_ml_pipeline_v2/lib/python3.11/site-packages (2.0.0rc3)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/eeg_ml_pipeline_v2/lib/python3.11/site-packages (from specparam) (2.0.2)\n",
      "Requirement already satisfied: scipy>=0.19 in /opt/miniconda3/envs/eeg_ml_pipeline_v2/lib/python3.11/site-packages (from specparam) (1.15.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Not availble through a Conda install/environment\n",
    "%pip install specparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9880e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# MNE-Python\n",
    "import mne\n",
    "\n",
    "# Specparam\n",
    "from specparam import SpectralGroupModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466737ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fooof version: 2.0.0rc3\n"
     ]
    }
   ],
   "source": [
    "# Check the version of the module\n",
    "from specparam import __version__ as specparam_version\n",
    "print('Current fooof version:', specparam_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d850378",
   "metadata": {},
   "source": [
    "# Classes & Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf4e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to establish relative paths for a given folder\n",
    "def get_folder_path(folder_name):\n",
    "    project_root = os.path.dirname(os.getcwd())\n",
    "    folder_path = os.path.join(project_root, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise Exception(f'Directory not found: {folder_path}')  \n",
    "     \n",
    "    return folder_path\n",
    "\n",
    "# Utility function to check for the existence of a file in a given directory\n",
    "def get_file_path(folder, file_name):\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f'File not found: {file_path}')\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf4e1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for the study / dataset information\n",
    "\n",
    "class Study:\n",
    "    \"\"\"\n",
    "    Class for information on an EEG study\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    TBD\n",
    "    \"\"\"\n",
    "\n",
    "    # BIDS structure source of subjects data\n",
    "    __subjects_source_file = 'participants.tsv'\n",
    "\n",
    "    def __init__(self, dataset_folder_path, dataset_name):\n",
    "        \"\"\"\n",
    "        Initialise Study instance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset_folder : str\n",
    "        dataset_name : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Study : class instance\n",
    "        \"\"\"\n",
    "\n",
    "        # Input validation - Valid Dataset\n",
    "        datasets_list = os.listdir(dataset_folder_path)\n",
    "        datasets_list = [d for d in datasets_list if d.startswith('ds') and os.path.isdir(os.path.join(dataset_folder_path, d))]\n",
    "\n",
    "        if dataset_name not in datasets_list:\n",
    "            raise ValueError(f\"Dataset '{dataset_name}' not found in available datasets: {datasets_list}\")\n",
    "        dataset_path = os.path.join(dataset_folder_path, dataset_name)\n",
    "        if not os.path.exists(dataset_path):\n",
    "            raise FileNotFoundError(f\"Path does not exist: {dataset_path}\")\n",
    "        subjects_file = os.path.join(dataset_folder_path, dataset_name, self.__subjects_source_file)\n",
    "        if not os.path.isfile(subjects_file):\n",
    "            raise ValueError(f'File not found: {subjects_file}')\n",
    "        \n",
    "        # Private Attributes\n",
    "        # TODO: Any private attributes?\n",
    "\n",
    "        # Public Attributes\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset_path = dataset_path\n",
    "        self.subjects_df = self._create_subjects_df(subjects_file)\n",
    "\n",
    "    def _create_subjects_df(self, subjects_csv):\n",
    "        # Read the datset csv file to get selected subjects data\n",
    "        try:\n",
    "            temp_subjects_df = pd.read_csv(subjects_csv, sep='\\t')\n",
    "        except Exception as e:\n",
    "            raise IOError(f\"Failed to read subjects file '{subjects_csv}': {e}\")\n",
    "        subjects_df = temp_subjects_df[['participant_id', 'AGE', 'GENDER', 'TYPE']].copy()\n",
    "        subjects_df.columns = ['subject_id', 'age', 'gender', 'pd']\n",
    "\n",
    "        return subjects_df\n",
    "    \n",
    "    # Public functions\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736591d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject Class with all EEG processing etc results\n",
    "\n",
    "class Subject:\n",
    "    \"\"\"\n",
    "    Class for information on an individual subject within an EEG study\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    TBD\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, study, subject_id):\n",
    "        \"\"\"\n",
    "        Initialise Subject instance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        study : Study class\n",
    "        subject_id : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Subject : class instance\n",
    "        \"\"\"\n",
    "\n",
    "        if 'verbose' in globals() and verbose:\n",
    "            mne.set_log_level('DEBUG')\n",
    "        else:\n",
    "            mne.set_log_level('WARNING')\n",
    "\n",
    "        # BIDS File Structure\n",
    "        #dataset_root = \n",
    "        #dataset_name = \n",
    "        subject = subject_id\n",
    "        session = ''\n",
    "        task = 'Rest'\n",
    "        datatype='eeg'\n",
    "\n",
    "        # EEGLab .set file name\n",
    "        temp_path = os.path.join(study.dataset_path, subject, session, datatype)\n",
    "        temp_file_name = subject + '_task-' + task + '_' + datatype + '.set'\n",
    "        eeg_lab_file_path = get_file_path(temp_path, temp_file_name)\n",
    "\n",
    "        # Get the raw EEG data & Inspect it\n",
    "        try:\n",
    "            self.eeg_raw = mne.io.read_raw_eeglab(eeg_lab_file_path, preload=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to load EEG data for subject {subject}: {e}\") \n",
    "\n",
    "        # TODO: Any raw data to keep in class? eg nchannels, sampling frequency ......      \n",
    "\n",
    "    \n",
    "    def inspect_EEG_Raw(self):\n",
    "        \"\"\"\n",
    "        Summarise the EEG information\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"EEG Raw Description: {self.eeg_raw.info['description']} on {self.eeg_raw.info['meas_date']}\")\n",
    "        print(self.eeg_raw)\n",
    "        print(self.eeg_raw.info)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42954154",
   "metadata": {},
   "source": [
    "# Pipeline Execute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95522dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------\n",
      "EEG Pipeline Parameters - Data\n",
      "EEG Source Datasets Folder: /Users/stuartgow/GitHub/EEG_ML_Pipeline/Data/EEG_Datasets_Source_exgithub\n",
      "EEG Study Features Folder: /Users/stuartgow/GitHub/EEG_ML_Pipeline/Data/EEG_Datasets_Processed\n"
     ]
    }
   ],
   "source": [
    "# Establish data paths & check EEG source datasets available\n",
    "#\n",
    "\n",
    "# Set progress messages\n",
    "global verbose\n",
    "verbose = True\n",
    "\n",
    "# Establish Data Folders\n",
    "eeg_datasets_source_folder = 'Data/EEG_Datasets_Source_exgithub'\n",
    "eeg_study_features_folder = 'Data/EEG_Datasets_Processed'\n",
    "\n",
    "\n",
    "eeg_datasets_path = get_folder_path(eeg_datasets_source_folder)\n",
    "eeg_study_features_path = get_folder_path(eeg_study_features_folder)\n",
    "\n",
    "# # Get a list of datasets in the EEG datasets source folder\n",
    "# datasets_list = os.listdir(eeg_datasets_path)\n",
    "# datasets_list = [d for d in datasets_list if d.startswith('ds') and os.path.isdir(os.path.join(eeg_datasets_path, d))]\n",
    "\n",
    "print('\\n---------------------------------')\n",
    "print('EEG Pipeline Parameters - Data')\n",
    "print(f'EEG Source Datasets Folder: {eeg_datasets_path}')\n",
    "# print('Datasets found:', datasets_list)\n",
    "print(f'EEG Study Features Folder: {eeg_study_features_path}')\n",
    "\n",
    "del eeg_datasets_source_folder, eeg_study_features_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30aeb194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "EEG Pipeline Processing start for study/dataset: ds004584-1.0.0 with 149 subjects\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Processing subject: sub-001\n",
      "Reading /Users/stuartgow/GitHub/EEG_ML_Pipeline/Data/EEG_Datasets_Source_exgithub/ds004584-1.0.0/sub-001/eeg/sub-001_task-Rest_eeg.fdt\n",
      "Reading 0 ... 140829  =      0.000 ...   281.658 secs...\n",
      "Cropping annotations 1970-01-01 00:00:00+00:00 - 1970-01-01 00:04:41.660000+00:00\n",
      "  [0] Keeping  (1970-01-01 00:00:00+00:00 - 1970-01-01 00:00:00+00:00 -> 0.0 - 0.0)\n",
      "Cropping complete (kept 1)\n",
      "EEG Raw Description: None on None\n",
      "<RawEEGLAB | sub-001_task-Rest_eeg.fdt, 63 x 140830 (281.7 s), ~67.8 MiB, data loaded>\n",
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, Fz, F3, F7, FT9, FC5, FC1, C3, T7, TP9, CP5, CP1, P3, P7, ...\n",
      " chs: 63 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 66 items (3 Cardinal, 63 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 250.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 63\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      ">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wd/rhzj_w8570g_y66t6j6mh4zw0000gn/T/ipykernel_30016/1163890863.py:46: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  self.eeg_raw = mne.io.read_raw_eeglab(eeg_lab_file_path, preload=True)\n"
     ]
    }
   ],
   "source": [
    "# Execute the end to end pipeline for a given EEG source dataset\n",
    "#\n",
    "\n",
    "# Get a valid dataset and extract essential data\n",
    "study_details = Study(eeg_datasets_path, 'ds004584-1.0.0')\n",
    "\n",
    "print('\\n-----------------------------------------------------------------------------------------------')\n",
    "print(f'EEG Pipeline Processing start for study/dataset: {study_details.dataset_name} with {len(study_details.subjects_df)} subjects')\n",
    "\n",
    "# Process each subject in the dataset\n",
    "for idx, subject in study_details.subjects_df.iterrows():\n",
    "    print('\\n-----------------------------------------------------------------------------------------------')\n",
    "    print(f\"Processing subject: {subject['subject_id']}\")\n",
    "\n",
    "    subject_eeg = Subject(study_details, subject['subject_id'])\n",
    "    subject_eeg.inspect_EEG_Raw()\n",
    "\n",
    "    break\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_ml_pipeline_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
