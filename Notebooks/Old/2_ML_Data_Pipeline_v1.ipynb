{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095b6647",
   "metadata": {},
   "source": [
    "# EEG Machine Learning Data Prep Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf2539",
   "metadata": {},
   "source": [
    "## TO DO - To Review\n",
    "\n",
    "Projects:\n",
    "- Pickle: https://www.perplexity.ai/search/in-a-jupyter-notebook-i-have-c-0LbAAH9ITFGfcPYaWlrt6Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9990c076",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "General dependencies:\n",
    "- python = 3.11.13\n",
    "- numpy = 2.0.2\n",
    "- scipy = 1.15.3\n",
    "- pandas = 2.2.3\n",
    "- matplotlib = 3.10.3\n",
    "\n",
    "ML dependencies:\n",
    "- scikit-learn = 1.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea841715",
   "metadata": {},
   "source": [
    "# Imports & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36d4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b859d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to establish relative paths for a given folder\n",
    "def get_folder_path(folder_name, data_folder='Data'):\n",
    "    project_root = os.path.dirname(os.getcwd())\n",
    "    folder_path = os.path.join(project_root, data_folder, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise FileNotFoundError(f'Directory not found: {folder_path}')  \n",
    "    return folder_path\n",
    "\n",
    "# Utility function to create a new folder path, if not exists\n",
    "def make_folder_path(folder_name, data_folder='Data', exists_ok=True):\n",
    "    project_root = os.path.dirname(os.getcwd())\n",
    "    folder_path = os.path.join(project_root, data_folder, folder_name)\n",
    "    if os.path.exists(folder_path):\n",
    "        if not exists_ok:\n",
    "            raise FileExistsError(f\"Directory already exists: {folder_path}\")\n",
    "    else:\n",
    "        os.makedirs(folder_path)\n",
    "    return folder_path\n",
    "\n",
    " # Utility function to extend an existing folder path with a subfolder\n",
    "def extend_folder_path(base_folder, subfolder, exists_ok=True):\n",
    "    if not os.path.isdir(base_folder):\n",
    "        raise FileNotFoundError(f'Parent directory not found: {base_folder}')\n",
    "    extended_path = os.path.join(base_folder, subfolder)\n",
    "    if os.path.exists(extended_path):\n",
    "        if not exists_ok:\n",
    "            raise FileExistsError(f\"Directory already exists: {extended_path}\")\n",
    "    else:\n",
    "        os.makedirs(extended_path)\n",
    "    return extended_path\n",
    "\n",
    "# Utility function to check for the existence of a file in a given folder\n",
    "def get_file_path(folder, file_name):\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f'File not found: {file_path}')\n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e162bdf7",
   "metadata": {},
   "source": [
    "# Classes & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb58cff",
   "metadata": {},
   "source": [
    "# Setup & Features Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe26a0b",
   "metadata": {},
   "source": [
    "# Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b66f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Data Prep Pipeline Run Define & Setup\n",
    "#\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Study Details\n",
    "study_name = 'IOWA_Rest'\n",
    "dataset_ref = 'ds004584-1.0.0'\n",
    "# eeg_run_id = '20250619_no_preprocess'\n",
    "eeg_run_folder = 'EEG_Processing_ds004584-1.0.0_20250619_no_preprocess'\n",
    "# study_name = 'UNM_Oddball'\n",
    "# dataset_ref = 'ds003490-1.1.0'\n",
    "# eeg_run_id = '20250618'\n",
    "\n",
    "# Run/Test Mode\n",
    "test_mode = False\n",
    "\n",
    "# Execution Parameters\n",
    "run_summary = 'full_run'\n",
    "ml_params = {'models': 'none'\n",
    "            }\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# Get existing study details, if exists\n",
    "study_folder_path = get_folder_path('Study_' + study_name)\n",
    "study_info_df = pd.read_pickle(study_folder_path + '/study_inf_df.pkl', compression='zip')\n",
    "study_subjects_df = pd.read_pickle(study_folder_path + '/study_subjects_df.pkl', compression='zip')\n",
    "\n",
    "# Get all folder paths from study_info_df\n",
    "eeg_processing_results_path = study_info_df.loc[0, 'eeg_processing_results_path']\n",
    "ml_training_results_path = study_info_df.loc[0, 'ml_training_results_path']\n",
    "\n",
    "# Get EEG results folder\n",
    "eeg_results_run_path = os.path.join(eeg_processing_results_path, eeg_run_folder)\n",
    "if not os.path.isdir(eeg_results_run_path):\n",
    "    raise FileNotFoundError(f'Directory not found: {eeg_results_run_path}')\n",
    "\n",
    "# Establish a new ML Training Run\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "ml_run_id = f'ML_Training_{dataset_ref}_{current_date}_{run_summary}'\n",
    "ml_training_run_path = extend_folder_path(ml_training_results_path, ml_run_id, exists_ok=False)\n",
    "\n",
    "# Create run df and save\n",
    "ml_run_params_df = pd.DataFrame({\n",
    "    'ml_run_id': [ml_run_id],\n",
    "    'study_name': [study_name],\n",
    "    'dataset_ref': [dataset_ref],\n",
    "    'ml_params': [ml_params]\n",
    "})\n",
    "ml_run_params_df.to_pickle(ml_training_run_path + '/ml_run_params_df.pkl', compression='zip')\n",
    "\n",
    "# Set progress messages, testing\n",
    "if test_mode:\n",
    "    VERBOSE = True\n",
    "else:\n",
    "    VERBOSE = False\n",
    "\n",
    "del current_date, eeg_processing_results_path, eeg_run_folder, ml_training_results_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630b7a1",
   "metadata": {},
   "source": [
    "# Features Load & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f4a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the Features Prep Pipeline\n",
    "#\n",
    "\n",
    "# Get features superset created after EEG processing\n",
    "features_superset_df = pd.read_pickle(eeg_results_run_path + '/eeg_results_features_superset_df.pkl', compression='zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c6077f",
   "metadata": {},
   "source": [
    "# Features Inspection, Cleaning & Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_features_cleaned_df = eeg_results_features_superset_df.copy()\n",
    "\n",
    "# Drop some channels\n",
    "# TODO: Should this be in the EEG pipeline so that uniform features are produced?\n",
    "# Drop all columns with channel number greater than 63 .... ?? or delete row 63 as perhaps an error\n",
    "# TODO: This actually reduces the AUC!?\n",
    "cols_to_drop = [col for col in study_features_cleaned_df.columns if 'chn_' in col and int(col.split('_')[1]) > 63]\n",
    "study_features_cleaned_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Drop all columns containing 'error' or 'r_squared'\n",
    "# TODO: This doesn't make much difference to the predictions\n",
    "cols_to_drop = [col for col in study_features_cleaned_df.columns if 'error' in col or 'r_squared' in col]\n",
    "study_features_cleaned_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Drop all columns containing 'cf', 'bw', or 'pw'\n",
    "# TODO: This significantly reduces recall and AUC, false negatives and false positives are increased\n",
    "# cols_to_drop = [col for col in study_features_cleaned_df.columns if any(x in col for x in ['cf', 'bw', 'pw'])]\n",
    "# study_features_cleaned_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# TODO: Dropping all peiodic other than CF doesn't make much difference!!\n",
    "# cols_to_drop = [col for col in study_features_cleaned_df.columns if any(x in col for x in ['bw', 'pw'])]\n",
    "# study_features_cleaned_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Drop all columns containing 'offset' or 'exponent'\n",
    "# TODO: This reduces AUC and false positives are increased\n",
    "# cols_to_drop = [col for col in study_features_cleaned_df.columns if 'offset' in col or 'exponent' in col]\n",
    "# study_features_cleaned_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Drop features\n",
    "# # TODO: Increases false positives ....\n",
    "# dropped_variables = ['gender']\n",
    "# study_features_cleaned_df.drop(dropped_variables, axis=1, inplace=True)\n",
    "\n",
    "# # TODO: Increases false negatives, redices recall. ...... is this to be expected given the PD in age, look at control group ages?\n",
    "# dropped_variables = ['age']\n",
    "# study_features_cleaned_df.drop(dropped_variables, axis=1, inplace=True)\n",
    "\n",
    "# Drop features\n",
    "dropped_variables = ['subject_id']\n",
    "study_features_cleaned_df.drop(dropped_variables, axis=1, inplace=True)\n",
    "\n",
    "# Before and After\n",
    "print(eeg_results_features_superset_df.shape)\n",
    "print(study_features_cleaned_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bd675",
   "metadata": {},
   "source": [
    "# Data Split ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "targetName = \"pd\"\n",
    "featureNames = study_features_cleaned_df.columns[study_features_cleaned_df.columns != targetName]\n",
    "\n",
    "X = study_features_cleaned_df[featureNames]\n",
    "y = study_features_cleaned_df[targetName]\n",
    "\n",
    "# Split of training and testing data, 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "del targetName, featureNames, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a8a5d",
   "metadata": {},
   "source": [
    "# Transforms  ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a242ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a transformation for categorical and numerical features\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "print(f'Numerics {len(numerical_features)} \\n', numerical_features)\n",
    "print(f'Categoricals {len(categorical_features)} \\n', categorical_features)\n",
    "\n",
    "transformations = [\n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='infrequent_if_exist'), categorical_features),\n",
    "    # ('num', RobustScaler(), numerical_features) - more false positives\n",
    "    # ('num', StandardScaler(), numerical_features) - AUC reduced\n",
    "    # ('num', MinMaxScaler(), numerical_features) -more false positives & AUC reduced\n",
    "    ('num', 'passthrough', numerical_features)\n",
    "]\n",
    "\n",
    "# Add to pipeline, and later add other actions such as dropping rows, imputing etc etc\n",
    "data_prep_pipeline = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('col_transform', ColumnTransformer(transformers=transformations))\n",
    "])\n",
    "data_prep_pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88da6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the separate datasets\n",
    "X_train_transformed = data_prep_pipeline.transform(X_train)\n",
    "X_test_transformed = data_prep_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30facfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(f'Original: {eeg_results_features_superset_df.shape}')\n",
    "display(f'Cleaned: {study_features_cleaned_df.shape}')\n",
    "\n",
    "display(f'X_Train: {X_train_transformed.shape}')\n",
    "display(f'X_Test: {X_test_transformed.shape}')\n",
    "display(data_prep_pipeline.get_feature_names_out())\n",
    "feature_names = data_prep_pipeline.get_feature_names_out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_ml_pipeline_v2_20250617",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
