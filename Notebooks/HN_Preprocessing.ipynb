{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79a226-dc66-4cb0-b1d7-48a2c32553df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import scipy as sci\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import periodogram\n",
    "import mne\n",
    "import glob\n",
    "from autoreject import AutoReject\n",
    "from mne.preprocessing import ICA\n",
    "import mne_icalabel\n",
    "from mne_icalabel import label_components\n",
    "import pandas as pd\n",
    "from autoreject import get_rejection_threshold\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "plt.rcParams['savefig.dpi'] = 600\n",
    "\n",
    "\n",
    "# # Check if CUDA is available\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "# print(device)\n",
    "#\n",
    "# # Cuda\n",
    "# mne.set_config('MNE_CUDA_DEVICE', '0')\n",
    "# mne.utils.set_config('MNE_USE_CUDA', 'true')\n",
    "\n",
    "ar = AutoReject(cv=3, n_interpolate=[1, 4, 8, 16], consensus=[0.5, 1], random_state=313, n_jobs=-1,\n",
    "                thresh_method='bayesian_optimization', verbose=False)\n",
    "\n",
    "data_path = '/home/hno/datasets/update_for_hamzeh/Python/IOWA_DATA/IOWA_Processing/Public_Datasets/Raw_data/'\n",
    "\n",
    "files = glob.glob('/home/hno/datasets/update_for_hamzeh/Python/IOWA_DATA/IOWA_Processing/Public_Datasets/Raw_data//**/*.vhdr',\n",
    "                  recursive=True)\n",
    "\n",
    "save_root = '/home/hno/datasets/update_for_hamzeh/Python/IOWA_DATA/IOWA_Processing/results/'\n",
    "sbj_files = [file for file in files if '.vhdr' in file]\n",
    "sbj_files = sorted(sbj_files)\n",
    "parkinson = [PD for PD in sbj_files if 'PD' in PD]\n",
    "healthy = [HC for HC in sbj_files if 'Con' in HC]\n",
    "\n",
    "'''To match channels for all datasets, we selected SanDiego dataset's channel as reference, however, some datasets might \n",
    "not have all the channels for SanDiego dataset, so we also excluded them. These are all channels that seemed to be \n",
    "common for all existing datasets'''\n",
    "\n",
    "include_channels = ['Fz', 'Fp1', 'AF3', 'F7', 'F3', 'F4', 'AF4', 'Fp2', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'C3', 'Cz',\n",
    "                    'C4', 'CP1', 'CP2', 'CP5', 'CP6', 'PO4', 'PO3', 'P3', 'Pz', 'P4', 'P7', 'P8', 'O1', 'O2', 'Oz', 'T7', 'T8']\n",
    "# fmin = int(input('Enter Min Frequency: '))\n",
    "# fmax = int(input('Enter Max Frequency: '))\n",
    "# condition = ['PD vs HC', 'Parkinson', 'Control']\n",
    "# f_range = [fmin, fmax]\n",
    "# ######### Getting bad components ######\n",
    "groups = ['pd', 'hc']\n",
    "ica_rejected = dict()\n",
    "failed_subj = dict()\n",
    "bad_subj = dict()\n",
    "for group in groups:\n",
    "    ica_rejected[group] = dict()\n",
    "    failed_subj[group] = dict()\n",
    "    bad_subj[group] = dict()\n",
    "######################################################\n",
    "pd_result = dict()\n",
    "hc_result = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b6987-7d3b-4fd4-bc17-2cd743a5c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and channel information\n",
    "# data_path = '/path/to/your/data'\n",
    "# include_channels = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'T7', 'C3', 'Cz', 'C4', 'T8', 'P7', 'P3', 'Pz', 'P4', 'P8', 'O1', 'O2'] # Example channels\n",
    "\n",
    "# Frequency bands for analysis\n",
    "freqs = [\n",
    "    [1, 30], [1, 40], [1, 50], [1, 60], [1, 70], [1, 80], [1, 90],\n",
    "    [3, 30], [3, 40], [3, 50], [3, 60], [3, 70], [3, 80], [3, 90]\n",
    "]\n",
    "\n",
    "# Initialize AutoReject\n",
    "ar = AutoReject(n_interpolate=[1, 2, 4], random_state=42, n_jobs=-1, verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "'''You may not need this or you may need to change it based on your data naming'''\n",
    "def parse_parkinson_name(path):\n",
    "    \"\"\"Extracts and formats the subject name for the Parkinson group.\"\"\"\n",
    "    name = path.split('Raw_data')[-1].split('Rest/')[-1].split('.vhdr')[0]\n",
    "    if len(name) > 6:\n",
    "        name = f\"px{name.split('Rest_')[-1]}\"\n",
    "    return name\n",
    "\n",
    "def parse_healthy_name(path):\n",
    "    \"\"\"Extracts and formats the subject name for the Healthy group.\"\"\"\n",
    "    return path.split('_Rest/')[-1].split('.vhdr')[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_group_data(subjects, group_key, name_parser_func, f_range, save_path):\n",
    "    \"\"\"\n",
    "    Processes a group of subjects through the EEG pipeline.\n",
    "\n",
    "    Args:\n",
    "        subjects (list): List of file paths for the subjects in the group.\n",
    "        group_key (str): A short key for the group (e.g., 'pd' or 'hc').\n",
    "        name_parser_func (function): The function to use for parsing subject names.\n",
    "        f_range (list): The [fmin, fmax] frequency range for the current analysis.\n",
    "        save_path (str): The directory path to save results.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing dictionaries for results, failed subjects,\n",
    "               bad subjects, and rejected IC counts.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    failed_subjects = []\n",
    "    bad_subjects = []\n",
    "    rejected_ics = {}\n",
    "\n",
    "    for subj_path in subjects:\n",
    "        try:\n",
    "            name = name_parser_func(subj_path)\n",
    "            print(f\"Processing Subject: {name} for frequency range {f_range} Hz...\")\n",
    "\n",
    "            # 1. Load and Filter Data\n",
    "            raw = mne.io.read_raw_brainvision(subj_path, preload=True, verbose=False)\n",
    "            filtered = raw.copy().pick(picks=\"eeg\").filter(\n",
    "                l_freq=1, h_freq=100, method='iir', phase='zero', verbose=False\n",
    "            )\n",
    "\n",
    "            # 2. Set Montage and Pre-process\n",
    "            exclude_channels = list(set(filtered.info['ch_names']) - set(include_channels))\n",
    "            filtered.drop_channels(exclude_channels, on_missing='raise', verbose=False)\n",
    "            \n",
    "            # Use raw's montage for healthy, filtered's for parkinson\n",
    "            montage = filtered.get_montage()\n",
    "            filtered.set_montage(montage, match_case=False, verbose=False)\n",
    "            \n",
    "            filtered.apply_function(sci.signal.detrend, n_jobs=-1, channel_wise=True, type='linear', verbose=False)\n",
    "            filtered.set_eeg_reference(ref_channels='average', verbose=False)\n",
    "\n",
    "            # 3. ICA for Artifact Removal\n",
    "            ica = ICA(n_components=len(filtered.ch_names) - 1, max_iter=\"auto\", method=\"infomax\", random_state=313, fit_params=dict(extended=True))\n",
    "            ica.fit(filtered.copy(), verbose=False)\n",
    "\n",
    "            # 4. Label and Exclude Bad Components\n",
    "            ica_labels = label_components(filtered, ica, method='iclabel')\n",
    "            labels = ica_labels[\"labels\"]\n",
    "            exclude_idx = [i for i, label in enumerate(labels) if label != \"brain\"]\n",
    "            rejected_ics[name] = len(exclude_idx)\n",
    "\n",
    "            # Reject subject if too many components are bad\n",
    "            if len(np.unique(exclude_idx)) >= len(labels) * 0.8:\n",
    "                print(f'Too many components rejected for Subj {name}. Skipping.')\n",
    "                bad_subjects.append(subj_path)\n",
    "                continue\n",
    "\n",
    "            raw_ica = ica.apply(filtered.copy(), exclude=np.unique(exclude_idx), verbose=False)\n",
    "\n",
    "            # 5. Epoching and Auto-Rejection\n",
    "            epochs = mne.make_fixed_length_epochs(raw_ica, duration=1, overlap=0, preload=True, verbose=False)\n",
    "            epochs.apply_function(sci.signal.detrend, type='linear', verbose=False)\n",
    "\n",
    "            reject_criteria = get_rejection_threshold(epochs, verbose=False)\n",
    "            epochs.drop_bad(reject=reject_criteria, verbose=False)\n",
    "            \n",
    "            epochs_ar, _ = ar.fit_transform(epochs, return_log=True)\n",
    "            epochs_ar.pick(['eeg'])\n",
    "            \n",
    "            print(f'Number of rejected ICs for {name}: {rejected_ics[name]} out of {len(labels)}')\n",
    "            epochs_ar.save(os.path.join(save_path, f'{name}_epo.fif'), overwrite=True, verbose=False)\n",
    "            \n",
    "            '''For now you do not need to go though fooofing'''\n",
    "            # 6. Calculate FOOOF.\n",
    "        #     results[name] = cal_foof(\n",
    "        #         epochs_ar, f_range=f_range, low_freq_to_del=False,\n",
    "        #         high_freq_to_del=False, remove_line_noise=False\n",
    "        #     )\n",
    "\n",
    "        # except Exception as e:\n",
    "        #     print(f\"!!! Failed to process subject {subj_path}. Error: {e}\")\n",
    "        #     failed_subjects.append(subj_path)\n",
    "        #     continue\n",
    "            \n",
    "    return results, failed_subjects, bad_subjects, rejected_ics\n",
    "\n",
    "\n",
    "# --- Main Execution Loop ---\n",
    "\n",
    "for fmin, fmax in freqs:\n",
    "    f_range = [fmin, fmax]\n",
    "    save_fooof = f'/space/slow/hno/update_for_hamzeh/Python/IOWA_DATA/IOWA_Processing/Range_{fmin}-{fmax}_Hz'\n",
    "    os.makedirs(save_fooof, exist_ok=True)\n",
    "    print(f'\\n--- Starting Analysis for Frequency Range {f_range} Hz ---')\n",
    "\n",
    "    # Define configurations for each group\n",
    "    group_configs = {\n",
    "        'parkinson': {\n",
    "            'subjects': parkinson,\n",
    "            'key': 'pd',\n",
    "            'name_parser': parse_parkinson_name,\n",
    "            'rejected_ics_fname': 'PD_rejected_ICs.pkl',\n",
    "            'results_fname': 'parkinson.pkl'\n",
    "        },\n",
    "        'healthy': {\n",
    "            'subjects': healthy,\n",
    "            'key': 'hc',\n",
    "            'name_parser': parse_healthy_name,\n",
    "            'rejected_ics_fname': 'HC_rejected_ICs.pkl',\n",
    "            'results_fname': 'healthy.pkl'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    all_failed = {}\n",
    "    all_bad = {}\n",
    "\n",
    "    # Process each group using the unified function\n",
    "    for group_name, config in group_configs.items():\n",
    "        print(f\"\\n... Processing {group_name.capitalize()} Group ...\")\n",
    "        \n",
    "        group_results, failed, bad, ics = process_group_data(\n",
    "            subjects=config['subjects'],\n",
    "            group_key=config['key'],\n",
    "            name_parser_func=config['name_parser'],\n",
    "            f_range=f_range,\n",
    "            save_path=save_fooof\n",
    "        )\n",
    "        \n",
    "        all_failed[config['key']] = failed\n",
    "        all_bad[config['key']] = bad\n",
    "        \n",
    "        # Save results for the current group\n",
    "        with open(os.path.join(save_fooof, config['rejected_ics_fname']), 'wb') as f:\n",
    "            pickle.dump(ics, f)\n",
    "        \n",
    "        with open(os.path.join(save_fooof, config['results_fname']), 'wb') as f:\n",
    "            pickle.dump(group_results, f)\n",
    "\n",
    "    # Save combined lists of failed and bad subjects\n",
    "    with open(os.path.join(save_fooof, 'failed_subj.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_failed, f)\n",
    "        \n",
    "    with open(os.path.join(save_fooof, 'bad_subj.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_bad, f)\n",
    "\n",
    "print(\"\\n--- All Processing Complete ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
