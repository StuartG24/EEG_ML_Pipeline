{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15f8a81",
   "metadata": {},
   "source": [
    "# 2 ML Features Selection & Model Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaed2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save Current Session\n",
    "# import dill\n",
    "\n",
    "# dill.dump_session('temp_save_session.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a previous session\n",
    "# import dill\n",
    "\n",
    "# dill.load_session('temp_save_session.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca9bf7",
   "metadata": {},
   "source": [
    "# Imports & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39158ea0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86388717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import warnings\n",
    "from typing import Literal\n",
    "\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pickle\n",
    "import cloudpickle\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Custom Functions\n",
    "sys.path.append(os.path.abspath('../Notebooks/Utilities')) \n",
    "import cust_utilities as utils\n",
    "\n",
    "# Maths, Pandas etc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sci\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ML Prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "# ML Training\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from ml_utilities import ml_model_pipeline_details, grid_search_results, classification_metrics \n",
    "from ml_utilities import feature_importance, get_shap_importance, get_prediction_probabilities\n",
    "import shap\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ed1b6",
   "metadata": {},
   "source": [
    "## Results & Features Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca539e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for subject info\n",
    "#\n",
    "\n",
    "def subject_info_plot(subjects_df):\n",
    "\n",
    "    # PD & Gender\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    fig.suptitle('Study Subjects - PD & Gender', fontsize=18)\n",
    "\n",
    "    counts = subjects_df['pd'].value_counts()\n",
    "    axes[0].set_title('PD')\n",
    "    axes[0].bar(counts.index.astype(str), counts.values, color=['skyblue', 'skyblue'], edgecolor='black')\n",
    "    axes[0].set_xticks(range(len(counts.index)))\n",
    "    axes[0].set_xticklabels(['Yes', 'No'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[0].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    counts = subjects_df['gender'].value_counts()\n",
    "    axes[1].set_title('Gender')\n",
    "    axes[1].bar(counts.index.astype(str), counts.values, color=['skyblue', 'skyblue'], edgecolor='black')\n",
    "    axes[1].set_xticks(range(len(counts.index)))\n",
    "    axes[1].set_xticklabels(['Male', 'Female'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[1].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Age Distribution & Box\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    fig.suptitle('Study Subjects - Age Distribution', fontsize=18)\n",
    "\n",
    "    axes[0].hist(subjects_df['age'], bins=15, color='skyblue', edgecolor='black')\n",
    "\n",
    "    axes[1].set_xticks([0])\n",
    "    box = axes[1].boxplot(subjects_df['age'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9095073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for EEG Preprocessing Results\n",
    "#\n",
    "\n",
    "def eeg_preprocess_results_plot(results_df):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "    fig.suptitle('EEG Preprocessing Metrics - All Subjects', fontsize=18)\n",
    "\n",
    "    # Quality Warning\n",
    "    counts = results_df['EEG_preprocessing_quality_warning'].value_counts().reindex([True, False], fill_value=0)\n",
    "    axes[0].set_title('Overall Quality Warning Count')\n",
    "    axes[0].bar(counts.index.astype(str), counts.values, color=['salmon', 'lightgreen'], edgecolor='black')\n",
    "    axes[0].set_xticks(range(len(counts.index)))\n",
    "    axes[0].set_xticklabels(['Yes', 'No'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[0].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    # # Channels count\n",
    "    # counts = results_df['channel_count'].value_counts()\n",
    "    # axes[1].set_title('Channels Count')\n",
    "    # axes[1].bar(counts.index.astype(str), counts.values, color=['skyblue'], edgecolor='black')\n",
    "\n",
    "    # ICA Rejection Level\n",
    "    axes[1].set_title('ICA - ICs Rejection Level')\n",
    "    box = axes[1].boxplot(results_df['ICA_rejection_level'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # Epoch Rejection Level\n",
    "    axes[2].set_title('Epoch Rejection Level')\n",
    "    box = axes[2].boxplot(results_df['epoch_rejection_level'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "    # axes[2].set_xlabel('Epoch Rejection Level')\n",
    "    # axes[2].set_ylabel('Number of Subjects')\n",
    "    # axes[2].hist(results_df['epoch_rejection_level'], bins=10, color='skyblue', edgecolor='black')\n",
    "    # nonzero_epoch_rejection = results_df['epoch_rejection_level'][results_df['epoch_rejection_level'] > 0]\n",
    "    # axes[2].hist(nonzero_epoch_rejection, bins=15, color='salmon', edgecolor='black', alpha=0.7)\n",
    "    # for bar in axes[2].patches:\n",
    "    #     bar.set_width(bar.get_width() * 0.8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d485d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for EEG SpecParam Results\n",
    "#\n",
    "\n",
    "def eeg_specparam_results_plot(results_df):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "    fig.suptitle('EEG SpecParam Fit Metrics - All Subjects', fontsize=18)\n",
    "\n",
    "    # Quality Warning\n",
    "    counts = results_df['chn_SPM_fit_quality_warning'].value_counts().reindex([True, False], fill_value=0)\n",
    "    axes[0].set_title('Overall Quality Warning Count')\n",
    "    axes[0].bar(counts.index.astype(str), counts.values, color=['salmon', 'lightgreen'], edgecolor='black')\n",
    "    \n",
    "    axes[0].set_xticks(range(len(counts.index)))\n",
    "    axes[0].set_xticklabels(['Yes', 'No'])\n",
    "    for i, (label, count) in enumerate(counts.items()):\n",
    "        axes[0].text(i, count/2, str(count), ha='center', va='center', fontsize=12)\n",
    "\n",
    "    # Error Mean\n",
    "    axes[1].set_title('Error Mean')\n",
    "    box = axes[1].boxplot(results_df['chn_error_mean'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # R-Squared Mean\n",
    "    axes[2].set_title('R2 Mean')\n",
    "    box = axes[2].boxplot(results_df['chn_r2_mean'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Number of flagged channels\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(3, 4))\n",
    "    # fig.suptitle('EEG SpecParam Fit Metrics - Flagged Channels', fontsize=18)\n",
    "    flagged_counts = results_df['chn_flagged_channels'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    axes.set_title('Flagged Channels Count')\n",
    "    box = axes.boxplot(flagged_counts, patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='salmon')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28feac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Aperiodic Features Spread\n",
    "#\n",
    "\n",
    "def aperiodic_features_plot(results_df, level):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    fig.suptitle(f'Aperiodic Features - {level}', fontsize=18)\n",
    "\n",
    "    # Offset\n",
    "    axes[0].set_title('Offset')\n",
    "    box = axes[0].boxplot(results_df['offset'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # Exponent\n",
    "    axes[1].set_title('Exponent')\n",
    "    box = axes[1].boxplot(results_df['exponent'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Periodic Features Spread\n",
    "#\n",
    "\n",
    "def periodic_features_plot(results_df, level):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "    fig.suptitle(f'Periodic Features - {level}', fontsize=18)\n",
    "\n",
    "    # CF\n",
    "    axes[0].set_title('CF_0')\n",
    "    box = axes[0].boxplot(results_df['cf_0'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # PW\n",
    "    axes[1].set_title('PW_0')\n",
    "    box = axes[1].boxplot(results_df['pw_0'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # BW\n",
    "    axes[2].set_title('BW_0')\n",
    "    box = axes[2].boxplot(results_df['bw_0'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Aperiodic Peaks Count \n",
    "#\n",
    "\n",
    "def periodic_peaks_plot(results_df):\n",
    "\n",
    "    regions_df = results_df[results_df['channel'].isnull()].copy()\n",
    "    cf_cols = [col for col in regions_df.columns if col.startswith('cf_')]\n",
    "    regions_df['num_periodic_cf'] = regions_df[cf_cols].notnull().sum(axis=1)\n",
    "    \n",
    "    channels_df = results_df[results_df['region'].isnull()].copy()\n",
    "    cf_cols = [col for col in channels_df.columns if col.startswith('cf_')]\n",
    "    channels_df['num_periodic_cf'] = channels_df[cf_cols].notnull().sum(axis=1)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    fig.suptitle(f'Periodic Peaks Count', fontsize=18)\n",
    "\n",
    "    # Region\n",
    "    axes[0].set_title('Regions')\n",
    "    box = axes[0].boxplot(regions_df['num_periodic_cf'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    # Channel\n",
    "    axes[1].set_title('Channels')\n",
    "    box = axes[1].boxplot(channels_df['num_periodic_cf'].dropna(), patch_artist=True)\n",
    "    for patch in box['boxes']:\n",
    "        patch.set(facecolor='skyblue')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba6e54",
   "metadata": {},
   "source": [
    "# Run: 1. Study Load & Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a8e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study and Processing Run Details\n",
    "\n",
    "#---- Parameters --------------------------------\n",
    "# Study & Processing Run Details\n",
    "study_name = 'IOWA_Rest'\n",
    "eeg_features_run = '1b_EEG_Features_Results_Run_20250801_full_run'\n",
    "\n",
    "run_description = 'test_regions_aperiodic'\n",
    "# test_mode = False\n",
    "\n",
    "# Extraction Parameters\n",
    "extraction_params = {'features_detail_level': 'region',    # region or channel, default channels\n",
    "                     'subject_meta_include': False,\n",
    "                     'aperiodic_include': True,\n",
    "                     'periodic_include': False\n",
    "                    }\n",
    "model_training_params = {'EEG_features_source_run': eeg_features_run}\n",
    "#----------------------------------------------------\n",
    "\n",
    "# Get existing study details, if exists\n",
    "study_folder_path = utils.get_folder_path('Study_' + study_name)\n",
    "study_info = pd.read_pickle(study_folder_path + '/study_inf.pkl', compression='zip')\n",
    "study_subjects_df = pd.read_pickle(study_folder_path + '/study_subjects_df.pkl', compression='zip')\n",
    "\n",
    "# EEG Processing Results Data\n",
    "eeg_features_run_results_path = utils.get_folder_path(study_info['eeg_processing_results_path'] + '/' + eeg_features_run)\n",
    "eeg_features_run_details = pd.read_pickle(eeg_features_run_results_path + '/run_details.pkl', compression='zip')\n",
    "eeg_preprocessing_run = eeg_features_run_details['eeg_preprocessed_data']\n",
    "\n",
    "eeg_preprocessing_run_results_path = utils.get_folder_path(study_info['eeg_processing_results_path'] + '/' + eeg_preprocessing_run)\n",
    "eeg_preprocessed_data_path = utils.get_folder_path(eeg_preprocessing_run_results_path + '/Cleaned_files' )\n",
    "eeg_preprocessing_run_details = pd.read_pickle(eeg_preprocessing_run_results_path + '/run_details.pkl', compression='zip')\n",
    "eeg_processing_results_df = pd.read_pickle(eeg_features_run_results_path + '/eeg_processing_results_df.pkl', compression='zip')\n",
    "eeg_features_superset_df = pd.read_pickle(eeg_features_run_results_path + '/eeg_features_superset_df.pkl', compression='zip')\n",
    "eeg_features_flattened_df = pd.read_pickle(eeg_features_run_results_path + '/eeg_features_flattened_df.pkl', compression='zip')\n",
    "\n",
    "# Setup the extraction run and results folder & save params\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "run_name = f'2_Feature_Selection_Training_Run_{current_date}_{run_description}'\n",
    "run_results_path = utils.extend_folder_path(study_info['ml_training_results_path'], run_name, exists_ok=False)\n",
    "\n",
    "run_details = pd.Series({\n",
    "    'study_name': study_name,\n",
    "    'run_name': run_name,\n",
    "    'extraction_params': extraction_params,\n",
    "    'model_training_params': model_training_params\n",
    "    })\n",
    "run_details.to_pickle(run_results_path + '/run_details.pkl', compression='zip')\n",
    "\n",
    "# # Set progress messages, testing\n",
    "# if test_mode:\n",
    "#     VERBOSE = True\n",
    "#     TEST_SUBJECTS = [0,5,101]\n",
    "#     # TEST_CHANNELS = ['F5', 'C3', 'P3', 'F6', 'C6', 'P6']\n",
    "# else:\n",
    "#     VERBOSE = False\n",
    "#     TEST_SUBJECTS = []\n",
    "#     # TEST_CHANNELS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db334c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Run Details & Data Structures\n",
    "summary = f'EEG Processing Parameters'\n",
    "summary = summary + f\"\\n- Study: {study_info['study_name']} {study_info['dataset_ref']}\"\n",
    "summary = summary + f\"\\n- EEG Processing Run: {eeg_preprocessing_run_details['run_name']}\"\n",
    "summary = summary + f\"\\n-   Preprocess Params: {eeg_preprocessing_run_details['preprocess_params']}\"\n",
    "summary = summary + f\"\\n-   ICA Params: {eeg_preprocessing_run_details['artefact_params']}\"\n",
    "summary = summary + f\"\\n- EEG Features Run: {eeg_features_run}\"\n",
    "summary = summary + f\"\\n-   PSD Params: {eeg_features_run_details['psd_params']}\"\n",
    "summary = summary + f\"\\n-   SpecParam Params: {eeg_features_run_details['specparam_params']}\"\n",
    "summary = summary + f\"\\n- Features Selection Run: {run_name}\"\n",
    "summary = summary + f\"\\n-   Feature Selection Params: {run_details['extraction_params']}\"\n",
    "summary = summary + f\"\\n-   Model Training Params: {run_details['model_training_params']}\"\n",
    "\n",
    "print(f'{summary}\\n')\n",
    "\n",
    "# Processing Metrics\n",
    "print('EEG Processing Results')\n",
    "print(eeg_processing_results_df.shape)\n",
    "display(eeg_processing_results_df.head())\n",
    "\n",
    "print(f'Null Fits: {sum(eeg_processing_results_df[\"chn_null_fits\"])}')\n",
    "eeg_preprocess_results_plot(eeg_processing_results_df)\n",
    "eeg_specparam_results_plot(eeg_processing_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study Subjects Summary\n",
    "print('Study Subjects')\n",
    "print(study_subjects_df.shape)\n",
    "display(study_subjects_df.head())\n",
    "\n",
    "subject_info_plot(study_subjects_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a378311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install selenium\n",
    "# %pip install great_tables[extra]\n",
    "\n",
    "# from great_tables import GT\n",
    "# GT(study_subjects_df.head(10)).tab_header(title=\"Sample Table (First 10 Rows)\").fmt_number(columns=\"value_column\").save('temp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84559552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Superset \n",
    "print('EEG Features Superset')\n",
    "print(eeg_features_superset_df.shape)\n",
    "display(eeg_features_superset_df.head())\n",
    "\n",
    "# Features Flattened \n",
    "print('EEG Features Flattened')\n",
    "print(eeg_features_flattened_df.shape)\n",
    "display(eeg_features_flattened_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features - At Region & Channel Detail Level\n",
    "#\n",
    "\n",
    "regions_df = eeg_features_superset_df[eeg_features_superset_df['channel'].isnull()].copy()\n",
    "channels_df = eeg_features_superset_df[eeg_features_superset_df['region'].isnull()].copy()\n",
    "\n",
    "aperiodic_features_plot(regions_df, 'Regions')\n",
    "aperiodic_features_plot(channels_df, 'Channels')\n",
    "\n",
    "periodic_features_plot(regions_df, 'Regions')\n",
    "periodic_features_plot(channels_df, 'Channels')\n",
    "\n",
    "periodic_peaks_plot(eeg_features_superset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f34ca",
   "metadata": {},
   "source": [
    "# Run: 2. Split X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X features and y target\n",
    "# For Data Pipeline & ML Model Training\n",
    "#\n",
    "\n",
    "target_col_name = 'pd'\n",
    "feature_names = eeg_features_flattened_df.columns[eeg_features_flattened_df.columns != target_col_name]\n",
    "X = eeg_features_flattened_df[feature_names].copy()\n",
    "y = eeg_features_flattened_df[target_col_name].copy()\n",
    "\n",
    "# Data Split : Training & Test, 80:20. NB cross-validation will be performed using Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TODO: Different split?\n",
    "# split by *subjects*, not by raw rows\n",
    "# train_subj, test_subj = train_test_split(subjects, stratify=labels,\n",
    "#                                          test_size=.3, random_state=42)\n",
    "# X_train = eeg_long[eeg_long.subject_id.isin(train_subj)]\n",
    "# X_test  = eeg_long[eeg_long.subject_id.isin(test_subj)]\n",
    "# y_train = labels.loc[train_subj].values\n",
    "# y_test  = labels.loc[test_subj].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba79ccc",
   "metadata": {},
   "source": [
    "# Run: 3. Feature Selection, Data Cleaning & Pipeline Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748489d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using a Custom Transformer class\n",
    "#\n",
    "\n",
    "class FeatureSelection(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, features_detail_level='default', selected_features='default'):\n",
    "        # Parameters for the selection\n",
    "        self.features_detail_level = features_detail_level\n",
    "        self.selected_features = selected_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_temp_df = X.copy()\n",
    "        else:\n",
    "            raise ValueError(\"X must be a pandas DataFrame for feature selection.\")\n",
    "        \n",
    "        # Filter out features according to detail level, ie region or channel\n",
    "        drop_cols =[]\n",
    "        if self.features_detail_level == 'region':\n",
    "            drop_cols = drop_cols + [col for col in X_temp_df.columns if col.startswith('channel')]\n",
    "        elif self.features_detail_level == 'channel':\n",
    "            drop_cols = drop_cols +[col for col in X_temp_df.columns if col.startswith('region')]\n",
    "        else:\n",
    "            raise ValueError(f'Detail of {self.features_detail_level} is not region or channel')\n",
    "        X_temp_df = X_temp_df.drop(columns=drop_cols, errors='ignore')\n",
    "        \n",
    "        # Only retain columns whose names contain any of the selected features\n",
    "        X_temp_df = X_temp_df[[col for col in X_temp_df.columns if any(feat in col for feat in self.selected_features)]]\n",
    "       \n",
    "        self.selected_features_ = list(X_temp_df)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_temp_df = X.copy()\n",
    "        else:\n",
    "            raise ValueError(\"X must be a pandas DataFrame for feature selection.\")\n",
    "        \n",
    "        # Apply feature selection\n",
    "        return X[self.selected_features_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece9611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Selection & Cleaning Pipeline Establish & Train & Save\n",
    "#\n",
    "\n",
    "# TODO: Compare no scaling at all and model performance\n",
    "# TODO: Different scaling approaches?\n",
    "\n",
    "# Transformer for Features Selection\n",
    "detail_level = extraction_params['features_detail_level']\n",
    "selected_features = []\n",
    "if extraction_params['subject_meta_include']: selected_features += ['age', 'gender']\n",
    "if extraction_params['aperiodic_include']: selected_features += ['offset', 'exponent']\n",
    "if extraction_params['periodic_include']: selected_features += ['pw', 'bw', 'cf']\n",
    "\n",
    "feature_selector =  FeatureSelection(detail_level, selected_features)\n",
    "\n",
    "# Sub pipeline for numerical and categorical transformations\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    # ('scale_num', RobustScaler())\n",
    "    ('scale_num', RobustScaler(quantile_range=(10.0, 90.0)))\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "    # (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    # (\"encode_cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "    ('encode_cat', OneHotEncoder(drop='first', handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "cols_transform = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, make_column_selector(dtype_include=['float64', 'int64'])),\n",
    "    ('categorical', cat_pipeline, make_column_selector(dtype_include='object'))\n",
    "])\n",
    "\n",
    "# Setup & train/fit the overall pipeline\n",
    "features_prep_pipeline = Pipeline([\n",
    "    ('features_selection', feature_selector),\n",
    "    # ('drop_columns', dropper),\n",
    "    ('data_preprocess', cols_transform)\n",
    "    ])  \n",
    "features_prep_pipeline.fit(X_train)\n",
    "\n",
    "# Save the Data Prep Pipeline\n",
    "# Using cloudpickle in order to handle the custom transformer class\n",
    "cloudpickle.dump(features_prep_pipeline, open(run_results_path + '/' + 'features_prep_pipeline.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a14c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checkpoint - Pipeline\n",
    "\n",
    "# print(\"Feature Extraction Pipeline Steps:\")\n",
    "# for name, step in features_prep_pipeline.named_steps.items():\n",
    "#     print(f\"- {name}: {step}\")\n",
    "\n",
    "# print(\"\\nColumnTransformer Details:\")\n",
    "# ct = features_prep_pipeline.named_steps['data_preprocess']\n",
    "# for name, trans, cols in ct.transformers_:\n",
    "#     print(f\"- Transformer: {name}\")\n",
    "#     print(f\"    Columns: {cols}\")\n",
    "#     print(f\"    Transformer object: {trans}\\n\")\n",
    "\n",
    "# print(\"\\nAll Pipeline Parameters\")\n",
    "# for param, value in features_prep_pipeline.get_params().items():\n",
    "#     print(f\"- {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4b741",
   "metadata": {},
   "source": [
    "# Run: 4. Models Training on Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3835c24",
   "metadata": {},
   "source": [
    "## Data Transform With Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformations to X data & Inspect Results\n",
    "#\n",
    "\n",
    "X_train_transformed = features_prep_pipeline.transform(X_train)\n",
    "X_test_transformed = features_prep_pipeline.transform(X_test)\n",
    "\n",
    "# TODO: Examine the impact of scaling etc more closely eg some boxplots before and after .... how well has eg scaling worked?\n",
    "\n",
    "# Before & After Datasets\n",
    "print(\"Features Extraction vs Transformed Data Shapes\")\n",
    "print(f'- Original Features Selection: {eeg_features_flattened_df.shape}')\n",
    "print(f'- Original X_train: {X_train.shape} and y_train: {y_train.shape}')\n",
    "print(f'- Original X_test: {X_test.shape} and y_test: {y_test.shape}')\n",
    "print(f'- Transformed X_train: {X_train_transformed.shape}')\n",
    "print(f'- Transformed X_test: {X_test_transformed.shape}')\n",
    "\n",
    "# Data Pipeline - Features Transformed\n",
    "print(\"\\nTransformed Features:\")\n",
    "for name, transformer, columns in cols_transform.transformers_:\n",
    "    print(f\"- {name}: {len(columns) if hasattr(columns, '__len__') else 'Unknown'} columns\")\n",
    "\n",
    "feature_names = features_prep_pipeline.named_steps['data_preprocess'].get_feature_names_out()\n",
    "print(f'Feature Names: {len(feature_names)}')\n",
    "# print(feature_names)\n",
    "temp_names_X_train_df = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "temp_names_X_train_df.reset_index(drop=True, inplace=True)\n",
    "print(temp_names_X_train_df.shape)\n",
    "display(temp_names_X_train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e984c6e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a Model Pipeline - Using Processed Data used in Pipeline Fitting\n",
    "#\n",
    "\n",
    "# Pipeline, params & grid search define\n",
    "model_pipeline = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1, verbose=False))\n",
    "    ])\n",
    "\n",
    "grid_params = {\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss'],     # Default gini. Tree split evaluation function\n",
    "    'classifier__n_estimators': [100, 150],                       # Default 100. Number of trees\n",
    "    'classifier__max_depth': [3, 10, 15],                         # Default none, unlimited ... but don't want to overfit\n",
    "    # 'classifier__max_features': [0.8, 2],           # Default is sqrt\n",
    "    'classifier__max_leaf_nodes': [50, None],                     # Default none, unlimited\n",
    "    # 'randomforestclassifier__min_samples_split': [2, 5],\n",
    "    # 'classifier__class_weight': [None, 'balanced']              # Balanced gives more importance to minority classes ... ?? Improves recall at the expense of precision\n",
    "    } \n",
    "\n",
    "# # Straight k-fold cross-validation\n",
    "# grid_search = GridSearchCV(\n",
    "#     model_pipeline, grid_params, cv=5, n_jobs=-1,\n",
    "#     scoring='precision'\n",
    "#     )\n",
    "\n",
    "# Stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    model_pipeline, grid_params, cv=skf, n_jobs=-1,\n",
    "    scoring='precision'\n",
    "    # scoring='f1'\n",
    "    # scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "\n",
    "# Grid search run\n",
    "start_time = time.perf_counter()\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "duration = time.perf_counter() - start_time\n",
    "\n",
    "# Checkpoint - Model Training Details\n",
    "ml_model_pipeline_details(model_pipeline)\n",
    "print('\\n')\n",
    "grid_search_results(grid_search, duration)\n",
    "print(f'Best Model: \\n{grid_search.best_estimator_}')\n",
    "\n",
    "# Retain the best model & save it, as well aas the grid search\n",
    "model_randforest = grid_search.best_estimator_\n",
    "\n",
    "cloudpickle.dump(grid_search, open(run_results_path + '/' + 'grid_search_randforest.pkl', 'wb'))\n",
    "cloudpickle.dump(model_randforest, open(run_results_path + '/' + 'model_randforest.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictions & Evaluation\n",
    "#\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "y_pred = model_randforest.predict(X_test_transformed)\n",
    "y_probablities = model_randforest.predict_proba(X_test_transformed)\n",
    "duration = time.perf_counter() - start_time\n",
    "\n",
    "# Evaluate Prediction Results\n",
    "print('Model Prediction Results')\n",
    "print(f'Run Time: {duration:.4f}')\n",
    "classification_metrics(model_randforest, X_test_transformed, y_test, y_pred)\n",
    "\n",
    "# Assign Probabilities to Each Prediction\n",
    "get_prediction_probabilities(y_pred, y_probablities, y_test)\n",
    "\n",
    "# Feature Importance / Contribution\n",
    "feature_importance(model_randforest, features_prep_pipeline)\n",
    "features_importance_shap_df = get_shap_importance(X_train_transformed, X_test_transformed, model_randforest, features_prep_pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40042c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_predictions_custom_threshold(model, X, threshold=0.5):\n",
    "#     \"\"\"\n",
    "#     Make predictions with custom threshold to minimize false positives\n",
    "#     Higher threshold = fewer false positives, but potentially lower recall\n",
    "#     \"\"\"\n",
    "#     probabilities = model.predict_proba(X)\n",
    "#     predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "#     return predictions, probabilities\n",
    "\n",
    "\n",
    "# predictions, probabilities = make_predictions_custom_threshold(\n",
    "#     model_randforest, X_test_transformed, threshold=0.65\n",
    "# )\n",
    "\n",
    "# print(predictions)\n",
    "# print(probabilities[:10])\n",
    "\n",
    "# classification_metrics(model_randforest, X_test_transformed, y_test, predictions)\n",
    "\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07763b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# def find_optimal_threshold(model, X, y_true, metric='precision'):\n",
    "#     \"\"\"Find threshold that optimizes a specific metric\"\"\"\n",
    "#     probabilities = model.predict_proba(X)[:, 1]\n",
    "#     thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    \n",
    "#     best_threshold = 0.5\n",
    "#     best_score = 0\n",
    "    \n",
    "#     for threshold in thresholds:\n",
    "#         preds = (probabilities >= threshold).astype(int)\n",
    "        \n",
    "#         if metric == 'precision':\n",
    "#             score = precision_score(y_true, preds, zero_division=0)\n",
    "#         elif metric == 'recall':\n",
    "#             score = recall_score(y_true, preds, zero_division=0)\n",
    "        \n",
    "#         if score > best_score:\n",
    "#             best_score = score\n",
    "#             best_threshold = threshold\n",
    "    \n",
    "#     return best_threshold, best_score\n",
    "\n",
    "# best_theshold, best_score = find_optimal_threshold(model_randforest, X_test_transformed,y_test)\n",
    "# print(best_theshold, best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e54553",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2abfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# Pipeline, params & grid search define\n",
    "model_pipeline = Pipeline([\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "    ])\n",
    "\n",
    "grid_params = {\n",
    "    'classifier__solver': ['saga','liblinear', 'lbfgs'],          # Default is lbfgs. Saga with L1 or l2. Large dataset. liblinear small datasets, binary classifications\n",
    "    'classifier__penalty': ['l1', 'l2'],                        # Types of regulaisation\n",
    "    'classifier__C': [1, 10, 100],                 # Default 1. Strength of regularisation, smaller is stronger\n",
    "    'classifier__class_weight': [None, 'balanced'],           # Default None. Balanced seems to prevent near zero True predictions\n",
    "    'classifier__max_iter': [1000, 2500, 5000]                      # Default 100. \n",
    "}\n",
    "# scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# # Straight k-fold cross-validation\n",
    "# grid_search = GridSearchCV(\n",
    "#     model_pipeline, grid_params, cv=5, n_jobs=-1,\n",
    "#     scoring='precision'\n",
    "#     )\n",
    "\n",
    "# Stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    model_pipeline, grid_params, cv=skf, n_jobs=-1,\n",
    "    scoring='precision'\n",
    "    )\n",
    "\n",
    "# Grid search run\n",
    "start_time = time.perf_counter()\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "duration = time.perf_counter() - start_time\n",
    "\n",
    "# Checkpoint - Model Training Details\n",
    "ml_model_pipeline_details(model_pipeline)\n",
    "print('\\n')\n",
    "grid_search_results(grid_search, duration)\n",
    "print(f'Best Model: \\n{grid_search.best_estimator_}')\n",
    "\n",
    "# Retain the best model & save it, as well aas the grid search\n",
    "model_logreg = grid_search.best_estimator_\n",
    "\n",
    "cloudpickle.dump(grid_search, open(run_results_path + '/' + 'grid_search_logreg.pkl', 'wb'))\n",
    "cloudpickle.dump(model_logreg, open(run_results_path + '/' + 'model_logreg.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictions & Evaluation\n",
    "#\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "y_pred = model_logreg.predict(X_test_transformed)\n",
    "duration = time.perf_counter() - start_time\n",
    "\n",
    "# Evaluate Prediction Results\n",
    "print('Model Prediction Results')\n",
    "print(f'Run Time: {duration:.4f}')\n",
    "classification_metrics(model_logreg, X_test_transformed, y_test, y_pred)\n",
    "\n",
    "# Assign Probabilities to Each Prediction\n",
    "get_prediction_probabilities(y_pred, y_probablities, y_test)\n",
    "\n",
    "# Feature Importance / Contribution\n",
    "features_importance_shap_df = get_shap_importance(X_train_transformed, X_test_transformed, model_logreg, features_prep_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Predictions & Evaluation - With Thresholds\n",
    "# #\n",
    "\n",
    "# start_time = time.perf_counter()\n",
    "# y_pred = model_logreg.predict(X_test_transformed)\n",
    "# y_pred_prob = model_logreg.predict_proba(X_test_transformed)[:,1]\n",
    "# pred_threshold = 0.6\n",
    "# y_pred_threshold = (y_pred_prob > pred_threshold).astype(int)\n",
    "# duration = time.perf_counter() - start_time\n",
    "\n",
    "# # for i in range(25):\n",
    "# #     print(f' Binary: {y_pred[i]} vs Prob: {y_pred_prob[i]:.2f} vs {y_pred_threshold[i]}')\n",
    "\n",
    "# # Evaluate Prediction Results\n",
    "# print('Model Prediction Results')\n",
    "# print(f'Run Time: {duration:.4f}')\n",
    "# classification_metrics(model_logreg, X_test_transformed, y_test, y_pred_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc64bf",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Classifier\n",
    "\n",
    "# Pipeline, params & grid search define\n",
    "model_pipeline = Pipeline([\n",
    "    ('classifier', MLPClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "grid_params = {\n",
    "    'classifier__hidden_layer_sizes': [(50,50), (100,50)],             # Default, single layer of 100\n",
    "    # 'classifier__hidden_layer_sizes': [(50,), (100,), (50,50)],             # Default, single layer of 100\n",
    "    'classifier__activation': ['tanh', 'relu'],                      # Default: relu\n",
    "    # 'classifier__solver': ['adam', 'lbfgs', 'sgd'],                  # Default adam\n",
    "    'classifier__solver': ['adam'],                  # Default adam\n",
    "    'classifier__learning_rate_init': [0.00001, 0.0001, 0.001],\n",
    "    'classifier__alpha': [0.1],                              # default L2, 0.0001,\n",
    "    # 'classifier__early_stopping': [True],\n",
    "    'classifier__batch_size': ['auto'],\n",
    "    'classifier__max_iter': [1000]                            # Default 200\n",
    "}\n",
    "\n",
    "# # Straight k-fold cross-validation\n",
    "# grid_search = GridSearchCV(\n",
    "#     model_pipeline, grid_params, cv=5, n_jobs=-1,\n",
    "#     scoring='precision'\n",
    "#     )\n",
    "\n",
    "# Stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    model_pipeline, grid_params, cv=skf, n_jobs=-1,\n",
    "    scoring='precision'\n",
    "    )\n",
    "\n",
    "# Grid search run\n",
    "start_time = time.perf_counter()\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "duration = time.perf_counter() - start_time\n",
    "\n",
    "# Checkpoint - Model Training Details\n",
    "ml_model_pipeline_details(model_pipeline)\n",
    "print('\\n')\n",
    "grid_search_results(grid_search, duration)\n",
    "print(f'Best Model: \\n{grid_search.best_estimator_}')\n",
    "\n",
    "# Retain the best model & save it, as well aas the grid search\n",
    "model_mlpc = grid_search.best_estimator_\n",
    "\n",
    "cloudpickle.dump(grid_search, open(run_results_path + '/' + 'grid_search_mlpc.pkl', 'wb'))\n",
    "cloudpickle.dump(model_mlpc, open(run_results_path + '/' + 'model_mlpc.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ad958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictions & Evaluation\n",
    "#\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "y_pred = model_mlpc.predict(X_test_transformed)\n",
    "duration = time.perf_counter() - start_time\n",
    "\n",
    "# Evaluate Prediction Results\n",
    "print('Model Prediction Results')\n",
    "print(f'Run Time: {duration:.4f}')\n",
    "classification_metrics(model_mlpc, X_test_transformed, y_test, y_pred)\n",
    "\n",
    "# Assign Probabilities to Each Prediction\n",
    "get_prediction_probabilities(y_pred, y_probablities, y_test)\n",
    "\n",
    "# Feature Importance / Contribution\n",
    "features_importance_shap_df = get_shap_importance(X_train_transformed, X_test_transformed, model_mlpc, features_prep_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbb4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Predictions & Evaluation - With Thresholds\n",
    "# #\n",
    "\n",
    "# start_time = time.perf_counter()\n",
    "# y_pred = model_mlpc.predict(X_test_transformed)\n",
    "# y_pred_prob = model_mlpc.predict_proba(X_test_transformed)[:,1]\n",
    "# pred_threshold = 0.6\n",
    "# y_pred_threshold = (y_pred_prob > pred_threshold).astype(int)\n",
    "# duration = time.perf_counter() - start_time\n",
    "\n",
    "# # for i in range(25):\n",
    "# #     print(f' Binary: {y_pred[i]} vs Prob: {y_pred_prob[i]:.2f} vs {y_pred_threshold[i]}')\n",
    "\n",
    "# # Evaluate Prediction Results\n",
    "# print('Model Prediction Results')\n",
    "# print(f'Run Time: {duration:.4f}')\n",
    "# classification_metrics(model_mlpc, X_test_transformed, y_test, y_pred_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e87da8",
   "metadata": {},
   "source": [
    "# Run: 5. Models Training Separate or Combined Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92341f50",
   "metadata": {},
   "source": [
    "## Temp Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0955e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model Training Function\n",
    "#\n",
    "\n",
    "def model_train_RandForest(X_train, y_train, feature_selector=None, cols_transform=None):\n",
    "\n",
    "    # Use the data pipeline in the search\n",
    "    if feature_selector:\n",
    "        model_pipeline = Pipeline([\n",
    "            ('features_selection', feature_selector),\n",
    "            ('data_preprocess', cols_transform),\n",
    "            ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1, verbose=False))\n",
    "            ])\n",
    "\n",
    "        grid_params = {\n",
    "            'features_selection__features_detail_level': ['region'],\n",
    "            'features_selection__selected_features': [['exp', 'offset']],\n",
    "            'classifier__criterion': ['gini', 'entropy', 'log_loss'],     # Default gini. Tree split evaluation function\n",
    "            'classifier__n_estimators': [100, 150],                       # Default 100. Number of trees\n",
    "            'classifier__max_depth': [3, 10, 15],                         # Default none, unlimited ... but don't want to overfit\n",
    "            # 'classifier__max_features': [0.8, 2],                       # Default is sqrt\n",
    "            'classifier__max_leaf_nodes': [50, None],                     # Default none, unlimited\n",
    "            # 'randomforestclassifier__min_samples_split': [2, 5],\n",
    "            # 'classifier__class_weight': [None, 'balanced']              # Balanced gives more importance to minority classes ... ?? Improves recall at the expense of precision\n",
    "            }\n",
    "    else:\n",
    "        model_pipeline = Pipeline([\n",
    "            ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1, verbose=False))\n",
    "            ])\n",
    "\n",
    "        grid_params = {\n",
    "            'classifier__criterion': ['gini', 'entropy', 'log_loss'],     # Default gini. Tree split evaluation function\n",
    "            'classifier__n_estimators': [100, 150],                       # Default 100. Number of trees\n",
    "            'classifier__max_depth': [3, 10, 15],                         # Default none, unlimited ... but don't want to overfit\n",
    "            # 'classifier__max_features': [0.8, 2],                       # Default is sqrt\n",
    "            'classifier__max_leaf_nodes': [50, None],                     # Default none, unlimited\n",
    "            # 'randomforestclassifier__min_samples_split': [2, 5],\n",
    "            # 'classifier__class_weight': [None, 'balanced']              # Balanced gives more importance to minority classes ... ?? Improves recall at the expense of precision\n",
    "            }\n",
    "    \n",
    "    # # Straight k-fold cross-validation\n",
    "    # grid_search = GridSearchCV(\n",
    "    #     model_pipeline, grid_params, cv=5, n_jobs=-1,\n",
    "    #     scoring='precision'\n",
    "    #     )\n",
    "\n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(\n",
    "        model_pipeline, grid_params, cv=skf, n_jobs=-1,\n",
    "        scoring='precision'\n",
    "        # scoring='f1'\n",
    "        # scoring='roc_auc'\n",
    "        )\n",
    "\n",
    "    # Grid search run\n",
    "    start_time = time.perf_counter()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    duration = time.perf_counter() - start_time\n",
    "\n",
    "    # Trace - Model Training Details\n",
    "    ml_model_pipeline_details(model_pipeline)\n",
    "    print('')\n",
    "    grid_search_results(grid_search, duration)\n",
    "    print(f'Best Model: \\n{grid_search.best_estimator_}')\n",
    "\n",
    "    # Retain the best model & save it, as well as the grid search\n",
    "    model_randforest = grid_search.best_estimator_\n",
    "    cloudpickle.dump(grid_search, open(run_results_path + '/' + 'grid_search_randforest.pkl', 'wb'))\n",
    "    cloudpickle.dump(model_randforest, open(run_results_path + '/' + 'model_randforest.pkl', 'wb'))\n",
    "\n",
    "    return model_randforest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4913fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "#\n",
    "\n",
    "def eval_model(model, data_pipeline, X_train, X_test, y_test):\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_probablities = model.predict_proba(X_test)\n",
    "    duration = time.perf_counter() - start_time\n",
    "\n",
    "    # Evaluate Prediction Results\n",
    "    print('Model Prediction Results')\n",
    "    print(f'Run Time: {duration:.4f}')\n",
    "    classification_metrics(model, X_test, y_test, y_pred)\n",
    "\n",
    "    # Assign Probabilities to Each Prediction\n",
    "    get_prediction_probabilities(y_pred, y_probablities, y_test)\n",
    "\n",
    "    # Feature Importance / Contribution\n",
    "    # feature_importance(model, data_pipeline)\n",
    "    features_importance_shap_df = get_shap_importance(X_train, X_test, model, data_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a5b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3832fbae",
   "metadata": {},
   "source": [
    "## Data Transform & Models With Separate Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85379d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformations to X data & Inspect Results\n",
    "#\n",
    "\n",
    "X_train_transformed = features_prep_pipeline.transform(X_train)\n",
    "X_test_transformed = features_prep_pipeline.transform(X_test)\n",
    "\n",
    "# TODO: Examine the impact of scaling etc more closely eg some boxplots before and after .... how well has eg scaling worked?\n",
    "\n",
    "# Before & After Datasets\n",
    "print(\"Features Extraction vs Transformed Data Shapes\")\n",
    "print(f'- Original Features Selection: {eeg_features_flattened_df.shape}')\n",
    "print(f'- Original X_train: {X_train.shape} and y_train: {y_train.shape}')\n",
    "print(f'- Original X_test: {X_test.shape} and y_test: {y_test.shape}')\n",
    "print(f'- Transformed X_train: {X_train_transformed.shape}')\n",
    "print(f'- Transformed X_test: {X_test_transformed.shape}')\n",
    "\n",
    "# Data Pipeline - Features Transformed\n",
    "print(\"\\nTransformed Features:\")\n",
    "for name, transformer, columns in cols_transform.transformers_:\n",
    "    print(f\"- {name}: {len(columns) if hasattr(columns, '__len__') else 'Unknown'} columns\")\n",
    "\n",
    "feature_names = features_prep_pipeline.named_steps['data_preprocess'].get_feature_names_out()\n",
    "print(f'Feature Names: {len(feature_names)}')\n",
    "# print(feature_names)\n",
    "temp_names_X_train_df = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "temp_names_X_train_df.reset_index(drop=True, inplace=True)\n",
    "print(temp_names_X_train_df.shape)\n",
    "display(temp_names_X_train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33092bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_randforest = model_train_RandForest(X_train_transformed, y_train)\n",
    "eval_model(model_randforest, features_prep_pipeline, X_train_transformed, X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa9d25",
   "metadata": {},
   "source": [
    "## Combined Pipeline & Models Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d242af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a658e6a",
   "metadata": {},
   "source": [
    "# xxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "573706d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform ALL data, before feature selection\n",
    "#\n",
    "\n",
    "# Sub pipeline for numerical and categorical transformations\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    # ('scale_num', RobustScaler())\n",
    "    ('scale_num', RobustScaler(quantile_range=(10.0, 90.0)))\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "    # (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    # (\"encode_cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "    ('encode_cat', OneHotEncoder(drop='first', handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "cols_transform = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, make_column_selector(dtype_include=['float64', 'int64'])),\n",
    "    ('categorical', cat_pipeline, make_column_selector(dtype_include='object'))\n",
    "])\n",
    "\n",
    "# Setup & train/fit the pipeline\n",
    "X_train_temp = X_train.drop('subject_id', axis=1).copy()\n",
    "X_test_temp = X_test.drop('subject_id', axis=1).copy()\n",
    "data_prep_pipeline = Pipeline([\n",
    "    ('data_preprocess', cols_transform)\n",
    "    ])  \n",
    "data_prep_pipeline.fit(X_train_temp)\n",
    "\n",
    "# Apply to X Data\n",
    "X_train_transformed = data_prep_pipeline.transform(X_train_temp)\n",
    "X_test_transformed = data_prep_pipeline.transform(X_test_temp)\n",
    "\n",
    "# Before & After Datasets\n",
    "print(\"Features Extraction vs Transformed Data Shapes\")\n",
    "print(f'- Original Features Selection: {eeg_features_flattened_df.shape}')\n",
    "print(f'- Original X_train: {X_train.shape} and y_train: {y_train.shape}')\n",
    "print(f'- Original X_test: {X_test.shape} and y_test: {y_test.shape}')\n",
    "print(f'- Transformed X_train: {X_train_transformed.shape}')\n",
    "print(f'- Transformed X_test: {X_test_transformed.shape}')\n",
    "\n",
    "# Data Pipeline - Features Transformed\n",
    "print(\"\\nTransformed Features:\")\n",
    "for name, transformer, columns in cols_transform.transformers_:\n",
    "    print(f\"- {name}: {len(columns) if hasattr(columns, '__len__') else 'Unknown'} columns\")\n",
    "\n",
    "feature_names = data_prep_pipeline.named_steps['data_preprocess'].get_feature_names_out()\n",
    "print(f'Feature Names: {len(feature_names)}')\n",
    "# print(feature_names)\n",
    "temp_names_X_train_df = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "temp_names_X_train_df.reset_index(drop=True, inplace=True)\n",
    "print(temp_names_X_train_df.shape)\n",
    "display(temp_names_X_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef241ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the Skeleton Pipelines\n",
    "\n",
    "feature_selector = FeatureSelection()\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    # ('scale_num', RobustScaler())\n",
    "    ('scale_num', RobustScaler(quantile_range=(10.0, 90.0)))\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "    # (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    # (\"encode_cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "    ('encode_cat', OneHotEncoder(drop='first', handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "cols_transform = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, make_column_selector(dtype_include=['float64', 'int64'])),\n",
    "    ('categorical', cat_pipeline, make_column_selector(dtype_include='object'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ba43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_importanceNew(X_train, X_test, model, data_pipeline):\n",
    "\n",
    "    def model_predict(X):\n",
    "        return model.predict_proba(X)[:, 1] \n",
    "        return \n",
    "    \n",
    "    \n",
    "    # Select a small background dataset (e.g., 100 samples)\n",
    "    background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]\n",
    "\n",
    "    # Get SHAP Values\n",
    "    explainer = shap.KernelExplainer(model_predict, background)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Get mean absolute SHAP values for global importance\n",
    "    global_importance = np.abs(shap_values).mean(axis=0)\n",
    "    importance_percentages = (global_importance / global_importance.sum()) * 100\n",
    "    # feature_ranking = np.argsort(global_importance)[::-1]\n",
    "\n",
    "    # Create df with names and importance\n",
    "    feature_names = data_pipeline.named_steps['data_preprocess'].get_feature_names_out()\n",
    "    shap_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance_%': importance_percentages\n",
    "    }).sort_values(by='importance_%', ascending=False).reset_index(drop=True)\n",
    "    # print(shap_importance_df.head())\n",
    "\n",
    "    # # Get feature names for the transformed data\n",
    "    # print('Top 5 Features by SHAP importance')\n",
    "    # for idx in feature_ranking[:5]:\n",
    "    #     print(f\"{feature_names[idx]}: {global_importance[idx]:.4f}\")\n",
    "    \n",
    "    # Plot the Top 25\n",
    "    print('SHAP Values Importance')\n",
    "    print(shap_importance_df.shape)\n",
    "    display(shap_importance_df.head())\n",
    "\n",
    "    importance_df = shap_importance_df.head(25)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(importance_df['feature'], importance_df['importance_%'], color='skyblue')\n",
    "    plt.xlabel('Importance %')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances (Sorted)')\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature at the top\n",
    "    plt.show()\n",
    "    \n",
    "    return shap_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ecfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate A Model\n",
    "#\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Need to transform the \n",
    "    xx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ed212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data preprocessing pipeline from the trained model\n",
    "#\n",
    "\n",
    "# Check if the model is a pipeline with preprocessing steps\n",
    "if hasattr(model_randforest, 'named_steps'):\n",
    "    print(\"Model is a pipeline with the following steps:\")\n",
    "    for step_name, step in model_randforest.named_steps.items():\n",
    "        print(f\"- {step_name}: {step}\")\n",
    "    \n",
    "    # Extract all preprocessing steps (everything except the final classifier)\n",
    "    preprocessing_steps = list(model_randforest.named_steps.items())[:-1]  # All steps except last\n",
    "    \n",
    "    if preprocessing_steps:\n",
    "        # Create a new pipeline with just the preprocessing steps\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        preprocessing_pipeline = Pipeline(preprocessing_steps)\n",
    "        \n",
    "        print(f\"\\nExtracted preprocessing pipeline with {len(preprocessing_steps)} steps:\")\n",
    "        for step_name, step in preprocessing_steps:\n",
    "            print(f\"- {step_name}: {step}\")\n",
    "        \n",
    "        # Transform the data using the preprocessing pipeline\n",
    "        print(f\"\\nOriginal X_train shape: {X_train.shape}\")\n",
    "        X_train_transformed = preprocessing_pipeline.transform(X_train)\n",
    "        print(f\"Transformed X_train shape: {X_train_transformed.shape}\")\n",
    "        \n",
    "        print(f\"Original X_test shape: {X_test.shape}\")\n",
    "        X_test_transformed = preprocessing_pipeline.transform(X_test)\n",
    "        print(f\"Transformed X_test shape: {X_test_transformed.shape}\")\n",
    "        \n",
    "        # Display sample of transformed data\n",
    "        if hasattr(X_train_transformed, 'shape') and len(X_train_transformed.shape) == 2:\n",
    "            print(f\"\\nSample of transformed data (first 5 rows, first 10 columns):\")\n",
    "            if isinstance(X_train_transformed, np.ndarray):\n",
    "                print(X_train_transformed[:5, :10])\n",
    "            else:\n",
    "                print(X_train_transformed[:5, :10])\n",
    "    \n",
    "    else:\n",
    "        print(\"No preprocessing steps found in the model pipeline\")\n",
    "        preprocessing_pipeline = None\n",
    "\n",
    "else:\n",
    "    print(\"Model is not a pipeline - it's a single estimator\")\n",
    "    print(f\"Model type: {type(model_randforest)}\")\n",
    "    preprocessing_pipeline = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375e92e",
   "metadata": {},
   "source": [
    "# xxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765eedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a Model Pipeline - With Features Search\n",
    "#\n",
    "\n",
    "# Pipeline, params & grid search define\n",
    "model_pipeline = Pipeline([\n",
    "    ('features_select', FeatureSelection()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1, verbose=False))\n",
    "    ])\n",
    "\n",
    "grid_params = {\n",
    "    'features_select__features_detail_level': ['region', 'channel'],\n",
    "    'features_select__selected_features': [['exp', 'offset'], ['cf', 'pw']],\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss'],     # Default gini. Tree split evaluation function\n",
    "    'classifier__n_estimators': [150, 175],                       # Default 100. Number of trees\n",
    "    'classifier__max_depth': [2, 10, None],                       # Default none, unlimited\n",
    "    'classifier__max_leaf_nodes': [50, None],                     # Default none, unlimited\n",
    "    # 'randomforestclassifier__min_samples_split': [2, 5],\n",
    "    # 'classifier__class_weight': [None, 'balanced']\n",
    "                            # Balanced gives more importance to minority classes ... ?? Improves recall at the expense of precision\n",
    "    } \n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     model_pipeline, grid_params, \n",
    "#     cv=5,\n",
    "#     scoring='f1'\n",
    "#     )\n",
    "\n",
    "# Stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    model_pipeline, grid_params, cv=skf, n_jobs=-1,\n",
    "    scoring='precision'\n",
    "    )\n",
    "\n",
    "# Grid search run\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "grid_search.fit(X_train, y_train)\n",
    "duration = time.perf_counter() - start_time\n",
    "\n",
    "# Checkpoint - Model Training Details\n",
    "ml_model_pipeline_details(model_pipeline)\n",
    "print('\\n')\n",
    "grid_search_results(grid_search, duration)\n",
    "print(f'Best Model: \\n{grid_search.best_estimator_}')\n",
    "\n",
    "model_randforest_widesearch = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd17a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictions & Evaluation\n",
    "#\n",
    "model_randforest = grid_search.best_estimator_\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "y_pred = model_randforest.predict(X_test)\n",
    "duration = time.perf_counter() - start_time\n",
    "\n",
    "# Evaluate Prediction Results\n",
    "print('Model Prediction Results')\n",
    "print(f'Run Time: {duration:.4f}')\n",
    "classification_metrics(model_randforest, X_test, y_test, y_pred)\n",
    "\n",
    "# Feature Importance / Contribution\n",
    "# feature_importance(model_randforest, features_prep_pipeline)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_ml_pipeline_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
